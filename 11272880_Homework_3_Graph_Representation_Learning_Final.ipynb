{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11272880_Homework_3_Graph_Representation_Learning_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wrJNV7gMGrT"
      },
      "source": [
        "# Machine Learning II: Deep Learning and Applications\n",
        "# Homework 3\n",
        "\n",
        "**Due date: Apr 20**\n",
        "\n",
        "### Instructions\n",
        "- Make a copy of this notebook in your own Colab and complete the questions there.\n",
        "- You can add more cells if necessary. You may also add descriptions to your code, though it is not mandatory.\n",
        "- Make sure the notebook can run through by *Runtime -> Run all*. **Keep all cell outputs** for grading.\n",
        "- Submit the link of your notebook [here](https://docs.google.com/forms/d/e/1FAIpQLSd3LoRVwJ1Nc8hogOv76Y6_JbfPTdRzxUNfaU1ZV9GVaIZDSA/viewform?usp=sf_link). Please **enable editing or comments** so that you can receive feedback from TAs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akXQ0ljBMPCa"
      },
      "source": [
        "Install GraphVite and PyTorch. This may take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T58ca7kVSdP9"
      },
      "source": [
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!./Miniconda3-latest-Linux-x86_64.sh -b -p /usr/local -f\n",
        "\n",
        "!conda install -y -c milagraph -c conda-forge graphvite \\\n",
        "  python=3.6 cudatoolkit=10.0\n",
        "!conda install -y wurlitzer ipykernel\n",
        "\n",
        "import site\n",
        "site.addsitedir(\"/usr/local/lib/python3.6/site-packages\")\n",
        "%reload_ext wurlitzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t_9EtfSR_O-"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn\n",
        "import torch\n",
        "from torch import nn\n",
        "%matplotlib inline\n",
        "import graphvite as gv\n",
        "import graphvite.application as gap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLnj2dBbMRtH"
      },
      "source": [
        "## 1. Node embedding and visualization (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iZuvYpzFd4e"
      },
      "source": [
        "### 1) Node embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhqqdISEdOj9"
      },
      "source": [
        "In this part, we will implement unsupervised node embeddings, and evaluate the learned embeddings on some downstream tasks.\n",
        "\n",
        "Common packages for implementing node embeddings include\n",
        "- GraphVite: [Website][GV], [Tutorial][GV Example], [Example config][GV Config]\n",
        "- PyTorch BigGraph: [Website][PBG], [Document][PBG Example], [Example config][PBG Config]\n",
        "- Open NE: [Website][ONE], [Tutorial][ONE Example]\n",
        "\n",
        "[GV]: https://graphvite.io/\n",
        "[PBG]: https://torchbiggraph.readthedocs.io/\n",
        "[ONE]: https://github.com/thunlp/OpenNE\n",
        "[GV Example]: https://colab.research.google.com/drive/1J5sXHlMejovbYD4sHfyKUmwiUI2a8YsD#forceEdit=true&sandboxMode=true\n",
        "[PBG Example]: https://torchbiggraph.readthedocs.io/en/latest/configuration_file.html\n",
        "[ONE Example]: https://github.com/thunlp/OpenNE#example\n",
        "[GV Config]: https://graphvite.io/docs/latest/_downloads/8e1e8548e732f2b79c8698568dbcf185/quick_start.yaml\n",
        "[PBG Config]: https://github.com/facebookresearch/PyTorch-BigGraph/blob/master/torchbiggraph/examples/configs/livejournal_config.py\n",
        "\n",
        "The following scaffold is based on GraphVite. However, you can override it with any implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWEkvRv3dzHc"
      },
      "source": [
        "We carry out the experiments on BlogCatalog dataset, where each node corresponds to a blog user and each edge corresponds to their friendship. Some node has labels which indicate the user's interests.\n",
        "\n",
        "The dataset can be found in GraphVite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6l7kbHphXNY"
      },
      "source": [
        "The train file contains edge list of format `[head] [tail]`.\n",
        "\n",
        "The test file contains node labels of format `[node] [label]`. Note one node may have multiple labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7IYc-qWPImk",
        "outputId": "75d8969d-f343-4c29-bcac-4ef7561096d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(gv.dataset.blogcatalog.train)\n",
        "print(gv.dataset.blogcatalog.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.graphvite/dataset/blogcatalog/blogcatalog_train.txt\n",
            "/root/.graphvite/dataset/blogcatalog/blogcatalog_label.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRPRpn1thhSX"
      },
      "source": [
        "Now train the node embeddings. For GraphVite, the following steps are needed.\n",
        "\n",
        "- Create a GraphApplication instance\n",
        "- Load the training file to the application\n",
        "- Build the application\n",
        "- Train the application with hyperparameters\n",
        "\n",
        "Implement the missing steps in the following cell.\n",
        "\n",
        "**Note:** Due to the implementation of GraphVite, `batch_size` should always be divisible by `augmentation_step`, otherwise Colab would crash."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aQ93PFQR226",
        "outputId": "fb84f649-9833-4bbf-bfab-57d47a041c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# TODO: Implement the training and evaluation steps\n",
        "\n",
        "app = gap.GraphApplication(dim=128)              #create a GraphApplication instance\n",
        "app.load(file_name=gv.dataset.blogcatalog.train) #Load the training file to the application\n",
        "app.build()                                      #Build the application\n",
        "app.train()                                      #Train the application with hyperparameters\n",
        "app.node_classification(file_name=gv.dataset.blogcatalog.label, portions=(0.4,))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[time] GraphApplication.load: 0.0946014 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loading graph from /root/.graphvite/dataset/blogcatalog/blogcatalog_train.txt\n",
            "0.00018755%\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "Graph<uint32>\n",
            "------------------ Graph -------------------\n",
            "#vertex: 10308, #edge: 327429\n",
            "as undirected: yes, normalization: no\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[time] GraphApplication.build: 3.4543 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "GraphSolver<128, float32, uint32>\n",
            "----------------- Resource -----------------\n",
            "#worker: 1, #sampler: 1, #partition: 1\n",
            "tied weights: no, episode size: 200\n",
            "gpu memory limit: 15.6 GiB\n",
            "gpu memory cost: 51.5 MiB\n",
            "----------------- Sampling -----------------\n",
            "augmentation step: 2, shuffle base: 2\n",
            "random walk length: 40\n",
            "random walk batch size: 100\n",
            "#negative: 1, negative sample exponent: 0.75\n",
            "----------------- Training -----------------\n",
            "model: LINE\n",
            "optimizer: SGD\n",
            "learning rate: 0.025, lr schedule: linear\n",
            "weight decay: 0.005\n",
            "#epoch: 2000, batch size: 100000\n",
            "resume: no\n",
            "positive reuse: 1, negative weight: 5\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Batch id: 0 / 6548\n",
            "loss = 0\n",
            "Batch id: 1000 / 6548\n",
            "loss = 0.388419\n",
            "Batch id: 2000 / 6548\n",
            "loss = 0.382393\n",
            "Batch id: 3000 / 6548\n",
            "loss = 0.379102\n",
            "Batch id: 4000 / 6548\n",
            "loss = 0.376356\n",
            "Batch id: 5000 / 6548\n",
            "loss = 0.373141\n",
            "Batch id: 6000 / 6548\n",
            "loss = 0.369651\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[time] GraphApplication.train: 32.1707 s\n",
            "effective labels: 14472 / 14476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'macro-F1@40%': 0.26389971375465393, 'micro-F1@40%': 0.41672417521476746}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk2fxkTO8TXo"
      },
      "source": [
        "vertex_embeddings = app.solver.vertex_embeddings\n",
        "context_embeddings = app.solver.context_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9oorou8gyUj"
      },
      "source": [
        "Evaluate the learned embeddings on node classification task. Try to use different portions of labeled nodes to train the node classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXWqBCHFjoCR"
      },
      "source": [
        "\n",
        "\n",
        "|          | 10% | 20% | 30% | 40% |\n",
        "|----------|-----|-----|-----|-----|\n",
        "| macro-F1 | 0.209907    | 0.239002    | 0.256159   | 0.263890    |\n",
        "| micro-F1 |  0.355117   |  0.388256   | 0.406922    | 0.416724    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrsNEzGAMyfe"
      },
      "source": [
        "### 2) Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxr5bg4kk0MF"
      },
      "source": [
        "In this part, we will visualize the embeddings learned in the previous problem.\n",
        "\n",
        "Common packages for visualization include\n",
        "- GraphVite (LargeVis): [Website][GV], [Tutorial][GV Example]\n",
        "- tSNE-CUDA (t-SNE): [Website][TSNE], [Document][TSNE Example]\n",
        "- scikit-learn (t-SNE): [Website][SK], [Document][SK Example]\n",
        "\n",
        "[GV]: https://graphvite.io/\n",
        "[TSNE]: https://github.com/CannyLab/tsne-cuda\n",
        "[SK]: https://scikit-learn.org/stable/index.html\n",
        "\n",
        "[GV Example]: https://colab.research.google.com/drive/1xRPPeCC0GxhCKpAUQblPST60_XNai2bv#forceEdit=true&sandboxMode=true\n",
        "[TSNE Example]: https://github.com/CannyLab/tsne-cuda#installation\n",
        "[SK Example]: https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7NK9clnh60b"
      },
      "source": [
        "Implement the training of the visualization algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxr49SAHkOtF",
        "outputId": "88bb3d29-3821-4b36-de51-97708676eac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# TODO: Implement the training of visualization\n",
        "vapp = gap.VisualizationApplication(dim=2)\n",
        "vapp.load(vectors=vertex_embeddings, perplexity=30)\n",
        "vapp.build()\n",
        "vapp.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[time] VisualizationApplication.load: 4.82845 s\n",
            "[time] VisualizationApplication.build: 0.107756 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "KNNGraph<uint32>\n",
            "------------------ Graph -------------------\n",
            "#vertex: 10308, #nearest neighbor: 200\n",
            "perplexity: 30, vector normalization: yes\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "VisualizationSolver<2, float32, uint32>\n",
            "----------------- Resource -----------------\n",
            "#worker: 1, #sampler: 1, #partition: 1\n",
            "tied weights: yes, episode size: 200\n",
            "gpu memory limit: 13.7 GiB\n",
            "gpu memory cost: 49.3 MiB\n",
            "----------------- Sampling -----------------\n",
            "positive sample batch size: 2000\n",
            "#negative: 5, negative sample exponent: 0.75\n",
            "----------------- Training -----------------\n",
            "model: LargeVis\n",
            "optimizer: Adam\n",
            "learning rate: 0.5, lr schedule: linear\n",
            "weight decay: 1e-05\n",
            "beta1: 0.999, beta2: 0.99999, epsilon: 1e-08\n",
            "#epoch: 50, batch size: 100000\n",
            "resume: no\n",
            "positive reuse: 5, negative weight: 3\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "Batch id: 0 / 1030\n",
            "loss = 0\n",
            "Batch id: 1000 / 1030\n",
            "loss = 0.112844\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[time] VisualizationApplication.train: 5.19983 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE0gmqXvmK2i"
      },
      "source": [
        "Visualize the coordinates as a scatter plot.\n",
        "\n",
        "You may need to tune the `perplexity` in LargeVis / t-SNE to get a better structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlsIKNMS3sh8"
      },
      "source": [
        "  import pandas as pd\n",
        "\n",
        "label = pd.read_csv(gv.dataset.blogcatalog.label, header=None, sep='\\t').sort_values(1).sort_values(0)\n",
        "l = label.loc[(label[1]==1)|(label[1]==2), [0,1]].reset_index(drop=True)\n",
        "l[2]=0\n",
        "for i in range(945-1):\n",
        "  if l[0][i]==l[0][i+1]:\n",
        "    l[2][i] = 1\n",
        "label = label.merge(l, how='left', on=0).rename(columns={'1_x':1}).drop(columns=['1_y'])\n",
        "label['label']= np.where(label[2]==1, 3, np.where((label[1]==1)|(label[1]==2), label[1], 4))\n",
        "label = label.drop_duplicates(0, keep='first')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4o71dUlcEpM",
        "outputId": "7b3cdaa2-c4c3-43d5-9303-05ed834bd26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# TODO: Visualize the coordinates\n",
        "%matplotlib inline\n",
        "\n",
        "#vapp.visualization(Y=label['label'],figure_size=10, scale=2)\n",
        "\n",
        "fig = plt.figure()\n",
        "coordinates = vapp.solver.coordinates\n",
        "Y = np.asarray(label['label'])\n",
        "classes = sorted(np.unique(Y))\n",
        "mean = np.mean(coordinates, axis=0)\n",
        "std = np.std(coordinates, axis=0)\n",
        "inside = np.abs(coordinates - mean) < vapp.OUTLIER_THRESHOLD * std\n",
        "indexes, = np.where(np.all(inside, axis=1))\n",
        "coordinates = coordinates[indexes]\n",
        "Y = Y[indexes]\n",
        "classes = sorted(np.unique(Y))\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "ax = fig.gca()\n",
        "c = ['blue','green','red','0.75']\n",
        "for cls in classes:\n",
        "  indexes, = np.where(Y == cls)\n",
        "  ax.scatter(*coordinates[indexes].T, s=2, c=c[cls-1], zorder=-cls)\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.legend(classes, markerscale=6, loc=\"upper right\")          \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmrPua40iFFm"
      },
      "source": [
        "Use the node classification labels to pick two classes of nodes. Color these nodes in the plot.\n",
        "\n",
        "**Hint**: For those belonging to both classes, you can randomly assign it to one class, or use a third color to denote them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONYgTZKDpf3J"
      },
      "source": [
        "Are the node embeddings learned from BlogCatalog good? Why or why not?\n",
        "\n",
        "**Answer:** The visualisation builds a KNNGraph to represent the similarities between vectors. Since we cannot clearly see the distinction between the different labels and they are not grouped together, the node embeddings do not appear to be very good. The embeddings learned from BlogCatalog show little to no clustering of the data and the majority of the points appear in the centre of the mapping and tells us very little about the quality of the embedding. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQsvKNKOOFw4"
      },
      "source": [
        "## 2. Graph Convolutional Networks (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGYaqn2lob8G"
      },
      "source": [
        "For this part, we are going to implement the GCN model for node classification, where the Cora dataset is used for testing the model. \n",
        "\n",
        "The Cora dataset is avaible [here](https://drive.google.com/open?id=1wVguWcuHEfga09XgLPvC_PkRXTGEEInW). You could find several files there. Among those files, net.txt provides the edges between different nodes, and the three columns correspond to source nodes, target nodes and edge weights respectively. For feature.txt, it gives the features of nodes. For label.txt, it provides the node labels. train.txt, valid.txt, test.txt provide the training nodes, validation nodes and test nodes respectively.\n",
        "\n",
        "The goal is to train a model on the training nodes, and further apply the model for classifying test nodes. In this process, you may use the validation nodes for hyper-parameter tuning and early stopping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rm4-x_-lpvk"
      },
      "source": [
        "### 1) Implement the GCN model\n",
        "\n",
        "In the first step, please implement a GCN model in the following code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAMHDgFQVi5F",
        "outputId": "2b628c45-479e-4525-fa43-cf500b3059b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# We first download the repo to get access to data and some utility code (This is specifically for colab.)\n",
        "!rm -rf pygcn/\n",
        "!git clone https://github.com/tkipf/pygcn/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pygcn'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Total 78 (delta 0), reused 0 (delta 0), pack-reused 78\u001b[K\n",
            "Unpacking objects: 100% (78/78), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smD6N_q_V7vX"
      },
      "source": [
        "import os\n",
        "ROOT_DIR='pygcn/'\n",
        "DATA_DIR=os.path.join(ROOT_DIR, 'data/cora/') # this is where most of the data lives"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxZ2D6fjTj1w"
      },
      "source": [
        "# utils\n",
        "# credit: https://github.com/tkipf/pygcn\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def load_data(path=DATA_DIR, dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
        "                                        dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
        "                                    dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
        "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
        "                        shape=(labels.shape[0], labels.shape[0]),\n",
        "                        dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    features = normalize(features)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(140, 640)\n",
        "    idx_test = range(1708, 2708)\n",
        "\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnAPeKO4wBS4"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1uONp2EsVNJ",
        "outputId": "764406ab-a6f3-4ecd-96d7-f45462c9e4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Training settings\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "# Load data\n",
        "adj, features, labels, idx_train, idx_val, idx_test = load_data()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  features = features.cuda()\n",
        "  adj = adj.cuda()\n",
        "  labels = labels.cuda()\n",
        "  idx_train = idx_train.cuda()\n",
        "  idx_val = idx_val.cuda()\n",
        "  idx_test = idx_test.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cora dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTZUoAYCqSmA"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp_GZt7kloHR"
      },
      "source": [
        "# TODO: Implement GCN here\n",
        "import math\n",
        "import torch\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "\n",
        "class GraphConvolution(Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, nlayers):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.nlayers = nlayers\n",
        "        self.gc = GraphConvolution(nfeat, nclass)\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gcx = GraphConvolution(nhid, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "      if self.nlayers == 1:\n",
        "        x = F.relu(self.gc(x,adj))\n",
        "      else:\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        for i in range((self.nlayers-2)):\n",
        "          x = F.relu(self.gcx(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc2(x, adj)\n",
        "      return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iREo4of0qXwn"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXT1CSbvqcfr"
      },
      "source": [
        "import time\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "# Train a model\n",
        "def train(model, idx, optimizer, criterion):\n",
        "  epoch_loss, epoch_acc = 0,0\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  predictions = model(features, adj)\n",
        "  loss = criterion(predictions[idx], labels[idx])\n",
        "  acc = accuracy(predictions[idx], labels[idx])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  epoch_loss += loss.item()\n",
        "  epoch_acc += acc.item()\n",
        "  return epoch_loss, epoch_acc \n",
        "\n",
        "# Evaluate a model\n",
        "def evaluate(model, idx, criterion):\n",
        "  epoch_loss, epoch_acc = 0,0\n",
        "  model.eval()\n",
        "  predictions = model(features, adj)\n",
        "  loss = criterion(predictions[idx], labels[idx])\n",
        "  acc = accuracy(predictions[idx], labels[idx])\n",
        "  epoch_loss += loss.item()\n",
        "  epoch_acc += acc.item()\n",
        "  return epoch_loss, epoch_acc \n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_5KLA-qs9Cg",
        "outputId": "5a0c734c-d332-46b6-e572-c6ce9477437a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "# Parameters\n",
        "N_EPOCHS = 200\n",
        "n_epochs_stop = 10\n",
        "n_layers = [1,2,3,4,5,6,7,8,9,10]\n",
        "h_dims = [4,8,16,32,64,128]\n",
        "\n",
        "criterion = F.nll_loss\n",
        "results = []\n",
        "\n",
        "for i in n_layers:\n",
        "  print('\\nTrain for: a number of layers of {0}'.format(i))\n",
        "\n",
        "  # Model and optimizer\n",
        "  model = GCN(nfeat=features.shape[1],\n",
        "          nhid=16,\n",
        "          nclass=labels.max().item() + 1,\n",
        "          dropout=0.5,\n",
        "          nlayers=i)\n",
        "  optimizer = optim.Adam(model.parameters(),\n",
        "                      lr=0.01, \n",
        "                      weight_decay=5e-4)\n",
        "  \n",
        "  if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "  \n",
        "  best_valid_acc, best_model = 0.0, 0\n",
        "  \n",
        "  # Training\n",
        "  for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, idx_train, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, idx_val, criterion)\n",
        "\n",
        "    end_time = time.time()    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      best_model = model\n",
        "      save = 'Best Model: Epoch {0} | Train Loss: {1} | Train Acc: {2}, Val. Loss: {3} | Val. Acc: {4}'.format(epoch, train_loss, train_acc, valid_loss, best_valid_acc)\n",
        "    \n",
        "    #print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    #print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "  print(\"Optimization Finished!\")\n",
        "  print(save)\n",
        "  test_loss, test_acc = evaluate(best_model, idx_test, criterion)\n",
        "  print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}')\n",
        "  results.append(test_acc)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train for: a number of layers of 1\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 191 | Train Loss: 1.6591506004333496 | Train Acc: 0.5571428571428572, Val. Loss: 1.808594822883606 | Val. Acc: 0.372\n",
            "Test Loss: 1.832 | Test Acc: 0.32\n",
            "\n",
            "Train for: a number of layers of 2\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 111 | Train Loss: 0.6561869382858276 | Train Acc: 0.8857142857142857, Val. Loss: 0.8851757645606995 | Val. Acc: 0.81\n",
            "Test Loss: 0.869 | Test Acc: 0.74\n",
            "\n",
            "Train for: a number of layers of 3\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 119 | Train Loss: 0.2689119279384613 | Train Acc: 0.95, Val. Loss: 0.5959522128105164 | Val. Acc: 0.8180000000000001\n",
            "Test Loss: 0.986 | Test Acc: 0.68\n",
            "\n",
            "Train for: a number of layers of 4\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 199 | Train Loss: 0.31534990668296814 | Train Acc: 0.8928571428571428, Val. Loss: 1.219320297241211 | Val. Acc: 0.736\n",
            "Test Loss: 2.076 | Test Acc: 0.61\n",
            "\n",
            "Train for: a number of layers of 5\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 122 | Train Loss: 0.8459298014640808 | Train Acc: 0.6642857142857143, Val. Loss: 1.4636763334274292 | Val. Acc: 0.592\n",
            "Test Loss: 3.153 | Test Acc: 0.42\n",
            "\n",
            "Train for: a number of layers of 6\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 6 | Train Loss: 1.8993593454360962 | Train Acc: 0.19999999999999998, Val. Loss: 1.8633840084075928 | Val. Acc: 0.35000000000000003\n",
            "Test Loss: 1.889 | Test Acc: 0.29\n",
            "\n",
            "Train for: a number of layers of 7\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 194 | Train Loss: 0.21518661081790924 | Train Acc: 0.9, Val. Loss: 1.3711707592010498 | Val. Acc: 0.792\n",
            "Test Loss: 2.275 | Test Acc: 0.66\n",
            "\n",
            "Train for: a number of layers of 8\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 15 | Train Loss: 1.8422653675079346 | Train Acc: 0.3142857142857143, Val. Loss: 1.8637754917144775 | Val. Acc: 0.35000000000000003\n",
            "Test Loss: 1.893 | Test Acc: 0.29\n",
            "\n",
            "Train for: a number of layers of 9\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 3 | Train Loss: 1.925806999206543 | Train Acc: 0.1357142857142857, Val. Loss: 1.906410813331604 | Val. Acc: 0.35000000000000003\n",
            "Test Loss: 1.898 | Test Acc: 0.29\n",
            "\n",
            "Train for: a number of layers of 10\n",
            "Optimization Finished!\n",
            "Best Model: Epoch 13 | Train Loss: 1.8694347143173218 | Train Acc: 0.2642857142857143, Val. Loss: 1.8685956001281738 | Val. Acc: 0.35000000000000003\n",
            "Test Loss: 1.895 | Test Acc: 0.29\n",
            "[0.32, 0.742, 0.684, 0.609, 0.421, 0.295, 0.657, 0.295, 0.295, 0.295]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bMMRZpzmIYi"
      },
      "source": [
        "### 2) Performance w.r.t. the number of layers\n",
        "\n",
        "Most GNN models only use a few layers for information propagation. Otherwise, they may suffer from the over-smoothing problem. To look into that, please fill in the following table to show the performance of your GNN model with respect to the number of propagation layers.\n",
        "\n",
        "|               | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10|\n",
        "|---------------|---|---|---|---|---|---|---|---|---|---|\n",
        "| Test Accuracy | 0.3892  | 0.7906 | 0.6683  | 0.6823  | 0.48742  | 0.4386  | 0.2911   | 0.2911  | 0.2911   | 0.2911  |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoyeDxMynQRK"
      },
      "source": [
        "Given the above result, please write down your observation and the potential reason based on your understanding.\n",
        "\n",
        "**Observations:** The test accuracy drops as the number of layers increases. The test accuracy is best with two layers.\n",
        "\n",
        "**Reasons:** The reason for this is that as the depth of the GCN increases (i.e. the number of layers) the model may suffer from the over-smoothing problem. Over-smoothing hinders training because it isolates output representations from the input features with increasing layers. Stacking more layers also leads to the vanishing gradient problem, eventually leading to features converging to the same value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY0VnyY0nlyO"
      },
      "source": [
        "### 3) Performance w.r.t. the hidden dimension\n",
        "\n",
        "Another important hyperparameter for graph neural networks is the dimension of hidden layers. In this part, you need to try different dimensions for the hidden layers, and further fill in the table below.\n",
        "\n",
        "|               | 4 | 8 | 16| 32| 64|128|\n",
        "|---------------|---|---|---|---|---|---|\n",
        "| Test Accuracy | 0.735 | 0.787  | 0.837 | 0.832 | 0.828  | 0.825  |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAtCT0kUoTC9"
      },
      "source": [
        "Given the above result, please write down your observation and the potential reason based on your understanding.\n",
        "\n",
        "**Observations:** The test accuracy rises with the size of the dimension of hidden layers, peaks, and then slowly begins to drop.\n",
        "\n",
        "**Reasons:** The potential reason for this is that as the capacity increases, the model starts over-fitting to the training data and generalizes poorly to the testing data. In the case of 128 layers, the corresponding training accuracy was of 99.29%, which is a clear indicator of over-fitting (see the corresponding training example at the end of the Notebook)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKspqRY_-YSD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQJb55zq-gyh"
      },
      "source": [
        "## Hidden Layer Dimension of 128 Training Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_trI_nb1rAQ",
        "outputId": "cceb6394-7a82-4ba3-c0cb-14c3e8bc42a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = GCN(nfeat=features.shape[1],\n",
        "            nhid=128,\n",
        "            nclass=labels.max().item() + 1,\n",
        "            dropout=0.5,\n",
        "            nlayers=2)\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=0.01, \n",
        "                       weight_decay=5e-4)\n",
        "\n",
        "criterion = F.nll_loss\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    features = features.cuda()\n",
        "    adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "    \n",
        "N_EPOCHS = 200\n",
        "\n",
        "best_valid_acc = 0.0\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_loss, train_acc = train(model, idx_train, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, idx_val, criterion)\n",
        "\n",
        "  end_time = time.time()    \n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_acc > best_valid_acc:\n",
        "    best_valid_acc = valid_acc\n",
        "  \n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "test_loss, test_acc = evaluate(model, idx_test, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.060 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.968 |  Val. Acc: 18.67%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 14.00%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.894 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.856 |  Val. Acc: 43.67%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.843 | Train Acc: 39.29%\n",
            "\t Val. Loss: 1.810 |  Val. Acc: 37.67%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.790 | Train Acc: 39.29%\n",
            "\t Val. Loss: 1.766 |  Val. Acc: 36.33%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.731 | Train Acc: 40.00%\n",
            "\t Val. Loss: 1.725 |  Val. Acc: 37.33%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.678 | Train Acc: 42.14%\n",
            "\t Val. Loss: 1.689 |  Val. Acc: 40.33%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.623 | Train Acc: 45.71%\n",
            "\t Val. Loss: 1.656 |  Val. Acc: 41.00%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.595 | Train Acc: 43.57%\n",
            "\t Val. Loss: 1.628 |  Val. Acc: 41.00%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.566 | Train Acc: 45.71%\n",
            "\t Val. Loss: 1.601 |  Val. Acc: 42.00%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.519 | Train Acc: 45.71%\n",
            "\t Val. Loss: 1.574 |  Val. Acc: 44.33%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.478 | Train Acc: 46.43%\n",
            "\t Val. Loss: 1.545 |  Val. Acc: 45.33%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.437 | Train Acc: 47.86%\n",
            "\t Val. Loss: 1.515 |  Val. Acc: 45.67%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.395 | Train Acc: 49.29%\n",
            "\t Val. Loss: 1.485 |  Val. Acc: 47.67%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.348 | Train Acc: 51.43%\n",
            "\t Val. Loss: 1.455 |  Val. Acc: 50.33%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.307 | Train Acc: 57.14%\n",
            "\t Val. Loss: 1.426 |  Val. Acc: 57.00%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.267 | Train Acc: 63.57%\n",
            "\t Val. Loss: 1.397 |  Val. Acc: 62.00%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.223 | Train Acc: 66.43%\n",
            "\t Val. Loss: 1.367 |  Val. Acc: 63.33%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.154 | Train Acc: 74.29%\n",
            "\t Val. Loss: 1.337 |  Val. Acc: 65.67%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.135 | Train Acc: 77.86%\n",
            "\t Val. Loss: 1.306 |  Val. Acc: 67.00%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.084 | Train Acc: 78.57%\n",
            "\t Val. Loss: 1.273 |  Val. Acc: 67.67%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.038 | Train Acc: 78.57%\n",
            "\t Val. Loss: 1.238 |  Val. Acc: 69.67%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.005 | Train Acc: 81.43%\n",
            "\t Val. Loss: 1.205 |  Val. Acc: 71.33%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.979 | Train Acc: 83.57%\n",
            "\t Val. Loss: 1.172 |  Val. Acc: 71.67%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.927 | Train Acc: 85.71%\n",
            "\t Val. Loss: 1.140 |  Val. Acc: 73.00%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.882 | Train Acc: 85.00%\n",
            "\t Val. Loss: 1.110 |  Val. Acc: 73.33%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.839 | Train Acc: 87.14%\n",
            "\t Val. Loss: 1.083 |  Val. Acc: 74.67%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.814 | Train Acc: 87.86%\n",
            "\t Val. Loss: 1.056 |  Val. Acc: 78.00%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.797 | Train Acc: 87.14%\n",
            "\t Val. Loss: 1.031 |  Val. Acc: 79.00%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.732 | Train Acc: 87.14%\n",
            "\t Val. Loss: 1.008 |  Val. Acc: 80.33%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.718 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.987 |  Val. Acc: 80.00%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.714 | Train Acc: 91.43%\n",
            "\t Val. Loss: 0.967 |  Val. Acc: 81.00%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.652 | Train Acc: 92.14%\n",
            "\t Val. Loss: 0.948 |  Val. Acc: 81.33%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.649 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.929 |  Val. Acc: 81.00%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.627 | Train Acc: 92.14%\n",
            "\t Val. Loss: 0.909 |  Val. Acc: 81.33%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.581 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.890 |  Val. Acc: 81.33%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.580 | Train Acc: 92.86%\n",
            "\t Val. Loss: 0.871 |  Val. Acc: 81.67%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.564 | Train Acc: 92.86%\n",
            "\t Val. Loss: 0.854 |  Val. Acc: 82.00%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.540 | Train Acc: 92.86%\n",
            "\t Val. Loss: 0.839 |  Val. Acc: 81.67%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.511 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.826 |  Val. Acc: 81.67%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.538 | Train Acc: 92.86%\n",
            "\t Val. Loss: 0.814 |  Val. Acc: 81.33%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.492 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.805 |  Val. Acc: 81.00%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.484 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.797 |  Val. Acc: 80.33%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.488 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.790 |  Val. Acc: 80.67%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.451 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.783 |  Val. Acc: 81.00%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.431 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.775 |  Val. Acc: 81.33%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.447 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.767 |  Val. Acc: 81.67%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.418 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.760 |  Val. Acc: 81.00%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.413 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.752 |  Val. Acc: 81.33%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.398 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.745 |  Val. Acc: 81.33%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.403 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.738 |  Val. Acc: 81.33%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.407 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.733 |  Val. Acc: 81.67%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.391 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.731 |  Val. Acc: 81.33%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.380 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.728 |  Val. Acc: 81.33%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.371 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.725 |  Val. Acc: 81.67%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.357 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.720 |  Val. Acc: 81.33%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.350 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.716 |  Val. Acc: 81.33%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.330 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.713 |  Val. Acc: 81.33%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.336 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.711 |  Val. Acc: 81.00%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.346 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.709 |  Val. Acc: 81.33%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.342 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.707 |  Val. Acc: 81.33%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.325 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.703 |  Val. Acc: 81.33%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.324 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 81.67%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.331 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 81.67%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.322 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.686 |  Val. Acc: 81.33%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.313 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.682 |  Val. Acc: 81.00%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.318 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.678 |  Val. Acc: 80.67%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.304 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 80.67%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.314 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 80.67%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.289 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.678 |  Val. Acc: 81.33%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.281 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 81.00%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.305 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.681 |  Val. Acc: 81.00%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.298 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 81.33%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.288 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.672 |  Val. Acc: 81.33%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.282 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.670 |  Val. Acc: 81.00%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.283 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.667 |  Val. Acc: 81.00%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.271 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.666 |  Val. Acc: 80.67%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.268 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.666 |  Val. Acc: 80.67%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.260 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.664 |  Val. Acc: 80.67%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.282 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.660 |  Val. Acc: 80.67%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.274 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.657 |  Val. Acc: 81.67%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.257 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 81.00%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.264 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 81.33%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.277 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 81.67%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.255 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.657 |  Val. Acc: 81.00%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.262 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.659 |  Val. Acc: 81.00%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.262 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.660 |  Val. Acc: 80.67%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.273 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.658 |  Val. Acc: 81.00%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.250 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 81.00%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.253 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.652 |  Val. Acc: 81.00%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.259 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.653 |  Val. Acc: 81.00%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.254 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.654 |  Val. Acc: 80.67%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.242 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 81.00%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.253 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.654 |  Val. Acc: 81.67%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.233 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 82.33%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.251 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.653 |  Val. Acc: 82.33%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.227 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.651 |  Val. Acc: 82.33%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.263 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.650 |  Val. Acc: 81.33%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.251 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 81.00%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.220 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 81.33%\n",
            "Epoch: 101 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.222 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 81.33%\n",
            "Epoch: 102 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.232 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 81.00%\n",
            "Epoch: 103 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.241 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 80.67%\n",
            "Epoch: 104 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.227 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 81.33%\n",
            "Epoch: 105 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.221 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.644 |  Val. Acc: 81.67%\n",
            "Epoch: 106 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.225 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.644 |  Val. Acc: 81.67%\n",
            "Epoch: 107 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.241 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 82.00%\n",
            "Epoch: 108 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.216 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.651 |  Val. Acc: 81.67%\n",
            "Epoch: 109 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.218 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 81.00%\n",
            "Epoch: 110 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.217 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.644 |  Val. Acc: 81.00%\n",
            "Epoch: 111 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.237 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 81.33%\n",
            "Epoch: 112 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.209 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 81.33%\n",
            "Epoch: 113 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.212 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 81.33%\n",
            "Epoch: 114 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.218 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.33%\n",
            "Epoch: 115 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.216 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 80.00%\n",
            "Epoch: 116 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.224 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 80.00%\n",
            "Epoch: 117 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.230 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 80.33%\n",
            "Epoch: 118 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.197 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 80.67%\n",
            "Epoch: 119 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.211 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 81.33%\n",
            "Epoch: 120 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.205 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 81.00%\n",
            "Epoch: 121 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.217 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.632 |  Val. Acc: 81.00%\n",
            "Epoch: 122 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.206 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.632 |  Val. Acc: 82.00%\n",
            "Epoch: 123 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.216 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 81.00%\n",
            "Epoch: 124 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.198 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.67%\n",
            "Epoch: 125 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.210 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 80.33%\n",
            "Epoch: 126 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.215 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 80.33%\n",
            "Epoch: 127 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.210 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 80.67%\n",
            "Epoch: 128 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.196 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 81.00%\n",
            "Epoch: 129 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.201 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 81.00%\n",
            "Epoch: 130 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.206 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 80.67%\n",
            "Epoch: 131 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.195 | Train Acc: 100.00%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.33%\n",
            "Epoch: 132 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.198 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 81.00%\n",
            "Epoch: 133 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.189 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 81.00%\n",
            "Epoch: 134 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.207 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.632 |  Val. Acc: 81.00%\n",
            "Epoch: 135 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.193 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 81.33%\n",
            "Epoch: 136 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.218 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 81.00%\n",
            "Epoch: 137 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.194 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 80.67%\n",
            "Epoch: 138 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.179 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 80.67%\n",
            "Epoch: 139 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.188 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 80.33%\n",
            "Epoch: 140 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.193 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 81.00%\n",
            "Epoch: 141 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.191 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 81.00%\n",
            "Epoch: 142 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.193 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 80.67%\n",
            "Epoch: 143 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.185 | Train Acc: 100.00%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 80.00%\n",
            "Epoch: 144 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.182 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 79.67%\n",
            "Epoch: 145 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.178 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 79.67%\n",
            "Epoch: 146 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.188 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 80.00%\n",
            "Epoch: 147 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.190 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.624 |  Val. Acc: 81.00%\n",
            "Epoch: 148 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.195 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.621 |  Val. Acc: 82.00%\n",
            "Epoch: 149 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.198 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.624 |  Val. Acc: 81.67%\n",
            "Epoch: 150 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.202 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.627 |  Val. Acc: 81.67%\n",
            "Epoch: 151 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.199 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 81.33%\n",
            "Epoch: 152 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.185 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 81.00%\n",
            "Epoch: 153 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.196 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 80.33%\n",
            "Epoch: 154 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.182 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 79.67%\n",
            "Epoch: 155 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.179 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.33%\n",
            "Epoch: 156 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.181 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 80.33%\n",
            "Epoch: 157 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.192 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.626 |  Val. Acc: 81.00%\n",
            "Epoch: 158 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.170 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.626 |  Val. Acc: 80.67%\n",
            "Epoch: 159 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.178 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.627 |  Val. Acc: 80.67%\n",
            "Epoch: 160 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.180 | Train Acc: 100.00%\n",
            "\t Val. Loss: 0.630 |  Val. Acc: 80.67%\n",
            "Epoch: 161 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.182 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 80.00%\n",
            "Epoch: 162 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.186 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.33%\n",
            "Epoch: 163 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.185 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.33%\n",
            "Epoch: 164 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.194 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.67%\n",
            "Epoch: 165 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.182 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 80.67%\n",
            "Epoch: 166 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.177 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 80.67%\n",
            "Epoch: 167 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.167 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.33%\n",
            "Epoch: 168 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.175 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 79.67%\n",
            "Epoch: 169 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.190 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 79.33%\n",
            "Epoch: 170 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.174 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.632 |  Val. Acc: 79.67%\n",
            "Epoch: 171 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.168 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.632 |  Val. Acc: 79.67%\n",
            "Epoch: 172 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.180 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 80.33%\n",
            "Epoch: 173 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.175 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 80.00%\n",
            "Epoch: 174 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.166 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 79.67%\n",
            "Epoch: 175 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.177 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 80.00%\n",
            "Epoch: 176 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.176 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.644 |  Val. Acc: 80.33%\n",
            "Epoch: 177 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.180 | Train Acc: 100.00%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 80.33%\n",
            "Epoch: 178 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.173 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.67%\n",
            "Epoch: 179 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.172 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 80.67%\n",
            "Epoch: 180 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.176 | Train Acc: 100.00%\n",
            "\t Val. Loss: 0.626 |  Val. Acc: 81.33%\n",
            "Epoch: 181 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.177 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.622 |  Val. Acc: 80.67%\n",
            "Epoch: 182 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.169 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.623 |  Val. Acc: 80.00%\n",
            "Epoch: 183 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.171 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.627 |  Val. Acc: 80.33%\n",
            "Epoch: 184 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.167 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 79.33%\n",
            "Epoch: 185 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.169 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 80.33%\n",
            "Epoch: 186 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.157 | Train Acc: 100.00%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 80.00%\n",
            "Epoch: 187 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.167 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.67%\n",
            "Epoch: 188 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.175 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.33%\n",
            "Epoch: 189 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.172 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 80.33%\n",
            "Epoch: 190 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.179 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.632 |  Val. Acc: 80.00%\n",
            "Epoch: 191 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.168 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.627 |  Val. Acc: 80.00%\n",
            "Epoch: 192 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.162 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.623 |  Val. Acc: 80.33%\n",
            "Epoch: 193 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.185 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.622 |  Val. Acc: 81.00%\n",
            "Epoch: 194 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.173 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.625 |  Val. Acc: 80.67%\n",
            "Epoch: 195 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.164 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.630 |  Val. Acc: 80.00%\n",
            "Epoch: 196 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.159 | Train Acc: 100.00%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 80.00%\n",
            "Epoch: 197 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.165 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.00%\n",
            "Epoch: 198 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.171 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 80.00%\n",
            "Epoch: 199 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.161 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 80.00%\n",
            "Epoch: 200 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.166 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 80.67%\n",
            "Optimization Finished!\n",
            "Test Loss: 0.611 | Test Acc: 0.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuW6a1wxzfxE"
      },
      "source": [
        "## Hyperparameter Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKZ1EB6ewOmU",
        "outputId": "101bbc3e-ed0b-470d-e493-1206d0cc0811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "N_EPOCHS = 400\n",
        "n_epochs_stop = 100\n",
        "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5] \n",
        "dropout_rates = [0.25, 0.5, 0.75]\n",
        "\n",
        "criterion = F.nll_loss\n",
        "best_overall_valid_acc, save = 0.0, 0\n",
        "\n",
        "for d in dropout_rates:\n",
        "  for l in learning_rates:\n",
        "    print('\\nTrain for: learning rate {0}, droupout rate {1}'.format(l, d))\n",
        "    model = GCN(nfeat=features.shape[1],\n",
        "            nhid=16,\n",
        "            nclass=labels.max().item() + 1,\n",
        "            dropout=d,\n",
        "            nlayers=2)\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=l, \n",
        "                       weight_decay=5e-4)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "    \n",
        "    best_valid_acc = 0.0\n",
        "    for epoch in range(N_EPOCHS):\n",
        "      start_time = time.time()\n",
        "\n",
        "      train_loss, train_acc = train(model, idx_train, optimizer, criterion)\n",
        "      valid_loss, valid_acc = evaluate(model, idx_val, criterion)\n",
        "\n",
        "      end_time = time.time()    \n",
        "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "      if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        epochs_no_improve = 0\n",
        "        if valid_acc > best_overall_valid_acc:\n",
        "          best_overall_valid_acc = valid_acc\n",
        "          save = '\\nBest model: learning rate {0}, droupout rate {1}'.format(l, d)\n",
        "      else:\n",
        "        epochs_no_improve += 1\n",
        "        # Check early stopping condition\n",
        "        if epochs_no_improve == n_epochs_stop:\n",
        "          print('Early stopping!')\n",
        "          epochs_no_improve=0\n",
        "          break\n",
        "      \n",
        "      print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "print(save)\n",
        "print(best_overall_valid_acc)\n",
        "test_loss, test_acc = evaluate(model, idx_test, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\tTrain Loss: 0.333 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 80.60%\n",
            "Epoch: 272 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.281 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 81.00%\n",
            "Epoch: 273 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.289 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 80.80%\n",
            "Epoch: 274 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.326 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 80.60%\n",
            "Epoch: 275 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.304 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 80.80%\n",
            "Epoch: 276 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.310 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 80.60%\n",
            "Epoch: 277 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.308 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 81.20%\n",
            "Epoch: 278 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.304 | Train Acc: 93.57%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 80.60%\n",
            "Epoch: 279 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.280 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 80.00%\n",
            "Epoch: 280 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.306 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 80.20%\n",
            "Epoch: 281 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.327 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 80.20%\n",
            "Epoch: 282 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.335 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 80.00%\n",
            "Epoch: 283 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.321 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.650 |  Val. Acc: 80.20%\n",
            "Epoch: 284 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.277 | Train Acc: 100.00%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 80.20%\n",
            "Epoch: 285 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.345 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 80.20%\n",
            "Epoch: 286 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.288 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.644 |  Val. Acc: 80.60%\n",
            "Epoch: 287 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.326 | Train Acc: 93.57%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 80.40%\n",
            "Epoch: 288 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.298 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 80.80%\n",
            "Epoch: 289 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.269 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 80.40%\n",
            "Epoch: 290 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.302 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 80.80%\n",
            "Epoch: 291 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.319 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 80.20%\n",
            "Epoch: 292 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.281 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 80.40%\n",
            "Epoch: 293 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.335 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.651 |  Val. Acc: 79.80%\n",
            "Epoch: 294 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.285 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 79.40%\n",
            "Epoch: 295 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.286 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.657 |  Val. Acc: 79.60%\n",
            "Epoch: 296 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.261 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.654 |  Val. Acc: 79.60%\n",
            "Epoch: 297 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.311 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 79.80%\n",
            "Epoch: 298 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.275 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 80.40%\n",
            "Epoch: 299 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.332 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.00%\n",
            "Epoch: 300 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.282 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 79.80%\n",
            "Epoch: 301 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.289 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.00%\n",
            "Epoch: 302 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.297 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.20%\n",
            "Epoch: 303 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.299 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.20%\n",
            "Epoch: 304 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.282 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 80.00%\n",
            "Epoch: 305 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.325 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 80.00%\n",
            "Epoch: 306 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.322 | Train Acc: 93.57%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 80.20%\n",
            "Epoch: 307 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.302 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.40%\n",
            "Epoch: 308 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.303 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.20%\n",
            "Epoch: 309 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.268 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.20%\n",
            "Epoch: 310 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.283 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.40%\n",
            "Epoch: 311 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.293 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.40%\n",
            "Epoch: 312 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.298 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.40%\n",
            "Epoch: 313 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.319 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.20%\n",
            "Epoch: 314 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.266 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.40%\n",
            "Epoch: 315 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.279 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 80.20%\n",
            "Epoch: 316 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.297 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 80.20%\n",
            "Epoch: 317 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.266 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 80.20%\n",
            "Epoch: 318 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.285 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 79.60%\n",
            "Epoch: 319 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.268 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 79.40%\n",
            "Epoch: 320 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.323 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 79.20%\n",
            "Epoch: 321 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.284 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 79.20%\n",
            "Epoch: 322 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.284 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 79.20%\n",
            "Epoch: 323 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.291 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 79.40%\n",
            "Epoch: 324 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.284 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 79.60%\n",
            "Epoch: 325 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.277 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 79.80%\n",
            "Epoch: 326 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.302 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.00%\n",
            "Epoch: 327 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.269 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.40%\n",
            "Epoch: 328 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.316 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 80.40%\n",
            "Epoch: 329 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.266 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 80.40%\n",
            "Epoch: 330 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.290 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 80.40%\n",
            "Epoch: 331 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.288 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.40%\n",
            "Epoch: 332 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.290 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 80.20%\n",
            "Epoch: 333 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.284 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 80.00%\n",
            "Epoch: 334 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.275 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 79.80%\n",
            "Epoch: 335 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.269 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 79.60%\n",
            "Epoch: 336 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.298 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 79.80%\n",
            "Epoch: 337 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.335 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 79.80%\n",
            "Epoch: 338 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.273 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 79.80%\n",
            "Epoch: 339 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.311 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 79.60%\n",
            "Epoch: 340 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.316 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 79.40%\n",
            "Epoch: 341 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.273 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.20%\n",
            "Epoch: 342 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.273 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 80.60%\n",
            "Epoch: 343 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.286 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 80.00%\n",
            "Epoch: 344 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.306 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 80.00%\n",
            "Epoch: 345 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.281 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 79.80%\n",
            "Epoch: 346 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.272 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.638 |  Val. Acc: 79.80%\n",
            "Epoch: 347 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.288 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 79.60%\n",
            "Epoch: 348 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.268 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 79.40%\n",
            "Epoch: 349 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.324 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 79.40%\n",
            "Epoch: 350 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.284 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 79.40%\n",
            "Epoch: 351 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.273 | Train Acc: 95.00%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 79.40%\n",
            "Epoch: 352 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.260 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 79.60%\n",
            "Epoch: 353 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.234 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.635 |  Val. Acc: 79.40%\n",
            "Epoch: 354 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.264 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 79.40%\n",
            "Epoch: 355 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.258 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 79.60%\n",
            "Epoch: 356 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.262 | Train Acc: 98.57%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 79.20%\n",
            "Epoch: 357 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.285 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 79.40%\n",
            "Epoch: 358 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.293 | Train Acc: 95.71%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 79.60%\n",
            "Epoch: 359 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.260 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 79.40%\n",
            "Epoch: 360 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.272 | Train Acc: 99.29%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 79.20%\n",
            "Epoch: 361 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.261 | Train Acc: 97.86%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 79.40%\n",
            "Epoch: 362 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.278 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 79.20%\n",
            "Epoch: 363 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.262 | Train Acc: 96.43%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 78.60%\n",
            "Early stopping!\n",
            "\n",
            "Train for: learning rate 0.001, droupout rate 0.5\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.031 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.995 |  Val. Acc: 8.40%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.031 | Train Acc: 6.43%\n",
            "\t Val. Loss: 1.994 |  Val. Acc: 7.60%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.039 | Train Acc: 5.00%\n",
            "\t Val. Loss: 1.993 |  Val. Acc: 7.40%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.041 | Train Acc: 5.71%\n",
            "\t Val. Loss: 1.992 |  Val. Acc: 7.40%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.030 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.990 |  Val. Acc: 7.20%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.031 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.989 |  Val. Acc: 7.20%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.031 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 7.00%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.022 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.987 |  Val. Acc: 7.00%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.028 | Train Acc: 5.71%\n",
            "\t Val. Loss: 1.986 |  Val. Acc: 7.20%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.022 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.985 |  Val. Acc: 7.20%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.024 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.984 |  Val. Acc: 7.40%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.023 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.982 |  Val. Acc: 7.60%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.018 | Train Acc: 6.43%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.60%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.016 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.60%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.018 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.020 | Train Acc: 5.00%\n",
            "\t Val. Loss: 1.978 |  Val. Acc: 8.00%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.017 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.977 |  Val. Acc: 7.80%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.010 | Train Acc: 5.71%\n",
            "\t Val. Loss: 1.976 |  Val. Acc: 7.60%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.008 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.975 |  Val. Acc: 7.60%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.012 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.973 |  Val. Acc: 7.80%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.009 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.972 |  Val. Acc: 8.00%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.004 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.971 |  Val. Acc: 8.00%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.009 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.970 |  Val. Acc: 8.00%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.009 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.969 |  Val. Acc: 8.20%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.011 | Train Acc: 5.71%\n",
            "\t Val. Loss: 1.968 |  Val. Acc: 8.20%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.008 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.967 |  Val. Acc: 8.20%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.001 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.966 |  Val. Acc: 8.20%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.005 | Train Acc: 5.00%\n",
            "\t Val. Loss: 1.965 |  Val. Acc: 8.20%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.001 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.964 |  Val. Acc: 8.20%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.004 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.963 |  Val. Acc: 8.20%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.995 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.962 |  Val. Acc: 8.20%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.961 |  Val. Acc: 8.20%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.960 |  Val. Acc: 8.60%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.959 |  Val. Acc: 8.80%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.992 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.957 |  Val. Acc: 8.80%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.956 |  Val. Acc: 8.80%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.998 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.955 |  Val. Acc: 8.80%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.954 |  Val. Acc: 8.80%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.953 |  Val. Acc: 8.80%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.952 |  Val. Acc: 8.80%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.951 |  Val. Acc: 8.80%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.950 |  Val. Acc: 9.00%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.949 |  Val. Acc: 9.60%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.948 |  Val. Acc: 9.60%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.982 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.947 |  Val. Acc: 9.60%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.977 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.946 |  Val. Acc: 9.60%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.945 |  Val. Acc: 9.60%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.985 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.944 |  Val. Acc: 9.60%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 9.80%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 11.00%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 12.20%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 15.20%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.975 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 17.60%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.972 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 23.60%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.974 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 28.40%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.974 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 31.40%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 33.60%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.975 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 35.00%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.968 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 35.40%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 35.60%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 35.20%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 34.80%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 34.80%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 34.80%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 34.80%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 35.00%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 35.00%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 35.00%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 35.00%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 35.00%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.959 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 35.00%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.959 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 35.00%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.00%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 35.00%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.943 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.00%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.00%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.937 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.910 |  Val. Acc: 35.00%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.933 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.00%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.00%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.906 |  Val. Acc: 35.00%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.929 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.905 |  Val. Acc: 35.00%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.937 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.904 |  Val. Acc: 35.00%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.930 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.903 |  Val. Acc: 35.00%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.902 |  Val. Acc: 35.00%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.929 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.901 |  Val. Acc: 35.00%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.900 |  Val. Acc: 35.00%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.898 |  Val. Acc: 35.00%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.897 |  Val. Acc: 35.00%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.896 |  Val. Acc: 35.00%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.895 |  Val. Acc: 35.00%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.914 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.894 |  Val. Acc: 35.00%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.893 |  Val. Acc: 35.00%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.892 |  Val. Acc: 35.00%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.891 |  Val. Acc: 35.00%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.929 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.890 |  Val. Acc: 35.00%\n",
            "Epoch: 101 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.923 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.889 |  Val. Acc: 35.00%\n",
            "Epoch: 102 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.888 |  Val. Acc: 35.00%\n",
            "Epoch: 103 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.887 |  Val. Acc: 35.00%\n",
            "Epoch: 104 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.885 |  Val. Acc: 35.00%\n",
            "Epoch: 105 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.884 |  Val. Acc: 35.00%\n",
            "Epoch: 106 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.917 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.883 |  Val. Acc: 35.00%\n",
            "Epoch: 107 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.882 |  Val. Acc: 35.00%\n",
            "Epoch: 108 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.893 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.881 |  Val. Acc: 35.00%\n",
            "Epoch: 109 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.908 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.880 |  Val. Acc: 35.00%\n",
            "Epoch: 110 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.878 |  Val. Acc: 35.00%\n",
            "Epoch: 111 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.877 |  Val. Acc: 35.00%\n",
            "Epoch: 112 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.884 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.876 |  Val. Acc: 35.00%\n",
            "Epoch: 113 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.909 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.875 |  Val. Acc: 35.00%\n",
            "Epoch: 114 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.874 |  Val. Acc: 35.00%\n",
            "Epoch: 115 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.903 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.873 |  Val. Acc: 35.00%\n",
            "Epoch: 116 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.893 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.871 |  Val. Acc: 35.00%\n",
            "Epoch: 117 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.896 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.870 |  Val. Acc: 35.00%\n",
            "Epoch: 118 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.902 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.869 |  Val. Acc: 35.00%\n",
            "Epoch: 119 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.876 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 35.00%\n",
            "Epoch: 120 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.900 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.867 |  Val. Acc: 35.00%\n",
            "Epoch: 121 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.887 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.865 |  Val. Acc: 35.00%\n",
            "Epoch: 122 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.887 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.864 |  Val. Acc: 35.00%\n",
            "Epoch: 123 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.890 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.863 |  Val. Acc: 35.00%\n",
            "Epoch: 124 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.888 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.862 |  Val. Acc: 35.00%\n",
            "Epoch: 125 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.883 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.860 |  Val. Acc: 35.00%\n",
            "Epoch: 126 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.886 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.859 |  Val. Acc: 35.00%\n",
            "Epoch: 127 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.873 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.858 |  Val. Acc: 35.00%\n",
            "Epoch: 128 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.883 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.857 |  Val. Acc: 35.00%\n",
            "Epoch: 129 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.881 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.856 |  Val. Acc: 35.00%\n",
            "Epoch: 130 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.870 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.854 |  Val. Acc: 35.00%\n",
            "Epoch: 131 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.885 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.853 |  Val. Acc: 35.00%\n",
            "Epoch: 132 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.864 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.852 |  Val. Acc: 35.00%\n",
            "Epoch: 133 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.865 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.851 |  Val. Acc: 35.00%\n",
            "Epoch: 134 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.874 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.850 |  Val. Acc: 35.00%\n",
            "Epoch: 135 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.876 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.848 |  Val. Acc: 35.00%\n",
            "Epoch: 136 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.868 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.847 |  Val. Acc: 35.00%\n",
            "Epoch: 137 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.872 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.846 |  Val. Acc: 35.00%\n",
            "Epoch: 138 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.867 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.845 |  Val. Acc: 35.00%\n",
            "Epoch: 139 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.879 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.844 |  Val. Acc: 35.00%\n",
            "Epoch: 140 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.860 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.842 |  Val. Acc: 35.00%\n",
            "Epoch: 141 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.856 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.841 |  Val. Acc: 35.00%\n",
            "Epoch: 142 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.861 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.840 |  Val. Acc: 35.00%\n",
            "Epoch: 143 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.873 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.839 |  Val. Acc: 35.00%\n",
            "Epoch: 144 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.863 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.838 |  Val. Acc: 35.00%\n",
            "Epoch: 145 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.867 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.836 |  Val. Acc: 35.00%\n",
            "Epoch: 146 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.856 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.835 |  Val. Acc: 35.00%\n",
            "Epoch: 147 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.856 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.834 |  Val. Acc: 35.00%\n",
            "Epoch: 148 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.857 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.833 |  Val. Acc: 35.00%\n",
            "Epoch: 149 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.849 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.832 |  Val. Acc: 35.00%\n",
            "Epoch: 150 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.857 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.831 |  Val. Acc: 35.00%\n",
            "Epoch: 151 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.846 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.829 |  Val. Acc: 35.00%\n",
            "Epoch: 152 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.852 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.828 |  Val. Acc: 35.00%\n",
            "Epoch: 153 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.849 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.827 |  Val. Acc: 35.00%\n",
            "Epoch: 154 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.832 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.826 |  Val. Acc: 35.00%\n",
            "Epoch: 155 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.865 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.825 |  Val. Acc: 35.00%\n",
            "Epoch: 156 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.831 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.824 |  Val. Acc: 35.00%\n",
            "Epoch: 157 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.845 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.822 |  Val. Acc: 35.00%\n",
            "Epoch: 158 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.836 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.821 |  Val. Acc: 35.00%\n",
            "Epoch: 159 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.826 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.820 |  Val. Acc: 35.00%\n",
            "Early stopping!\n",
            "\n",
            "Train for: learning rate 0.0001, droupout rate 0.5\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.999 |  Val. Acc: 13.40%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.998 |  Val. Acc: 13.40%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.998 |  Val. Acc: 13.40%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.998 |  Val. Acc: 13.40%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.998 |  Val. Acc: 13.40%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.998 |  Val. Acc: 13.40%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.995 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.997 |  Val. Acc: 13.40%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.997 |  Val. Acc: 13.40%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.997 |  Val. Acc: 13.40%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.997 |  Val. Acc: 13.40%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.997 |  Val. Acc: 13.40%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.996 |  Val. Acc: 13.40%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.996 |  Val. Acc: 13.40%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.996 |  Val. Acc: 13.40%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.996 |  Val. Acc: 13.40%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.980 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.996 |  Val. Acc: 13.40%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.985 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.995 |  Val. Acc: 13.40%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.985 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.995 |  Val. Acc: 13.40%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.995 |  Val. Acc: 13.40%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.995 |  Val. Acc: 13.40%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.995 |  Val. Acc: 13.40%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.994 |  Val. Acc: 13.40%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.994 |  Val. Acc: 13.40%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.994 |  Val. Acc: 13.40%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.976 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.994 |  Val. Acc: 13.40%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.994 |  Val. Acc: 13.40%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.993 |  Val. Acc: 13.40%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.993 |  Val. Acc: 13.40%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.992 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.993 |  Val. Acc: 13.40%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.992 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.993 |  Val. Acc: 13.40%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.992 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.993 |  Val. Acc: 13.40%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.992 |  Val. Acc: 13.40%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.994 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.992 |  Val. Acc: 13.40%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.992 |  Val. Acc: 13.40%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.992 |  Val. Acc: 13.40%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.992 |  Val. Acc: 13.40%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.991 |  Val. Acc: 13.40%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.982 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.991 |  Val. Acc: 13.40%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.991 |  Val. Acc: 13.40%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.991 |  Val. Acc: 13.40%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.991 |  Val. Acc: 13.40%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.990 |  Val. Acc: 13.40%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.999 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.990 |  Val. Acc: 13.40%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.990 |  Val. Acc: 13.40%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.990 |  Val. Acc: 13.40%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.979 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.990 |  Val. Acc: 13.40%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.976 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.989 |  Val. Acc: 13.40%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.989 |  Val. Acc: 13.40%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.989 |  Val. Acc: 13.40%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.985 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.989 |  Val. Acc: 13.40%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.989 |  Val. Acc: 13.40%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.982 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 13.40%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 13.40%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 13.40%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 13.40%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.980 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 13.40%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.987 |  Val. Acc: 13.40%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.982 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.987 |  Val. Acc: 13.40%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.971 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.987 |  Val. Acc: 13.40%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.987 |  Val. Acc: 13.40%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.980 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.987 |  Val. Acc: 13.40%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.986 |  Val. Acc: 13.40%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.977 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.986 |  Val. Acc: 13.40%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.979 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.986 |  Val. Acc: 13.40%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.986 |  Val. Acc: 13.40%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.980 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.986 |  Val. Acc: 13.40%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.986 |  Val. Acc: 13.40%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.974 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.985 |  Val. Acc: 13.40%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.985 |  Val. Acc: 13.40%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.976 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.985 |  Val. Acc: 13.40%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.977 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.985 |  Val. Acc: 13.40%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.985 |  Val. Acc: 13.40%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.984 |  Val. Acc: 13.40%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.979 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.984 |  Val. Acc: 13.40%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.971 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.984 |  Val. Acc: 13.40%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.984 |  Val. Acc: 13.40%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.984 |  Val. Acc: 13.40%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.980 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.983 |  Val. Acc: 13.40%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.983 |  Val. Acc: 13.40%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.975 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.983 |  Val. Acc: 13.40%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.983 |  Val. Acc: 13.40%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.983 |  Val. Acc: 13.40%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.983 |  Val. Acc: 13.40%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.982 |  Val. Acc: 13.40%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.981 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.982 |  Val. Acc: 13.40%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.982 |  Val. Acc: 13.40%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.982 |  Val. Acc: 13.40%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.982 |  Val. Acc: 13.40%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 13.40%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 13.40%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 13.40%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.978 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 13.40%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 13.40%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.979 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 13.40%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 13.40%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 13.40%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.974 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 13.40%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.967 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 13.40%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 13.40%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 13.40%\n",
            "Early stopping!\n",
            "\n",
            "Train for: learning rate 1e-05, droupout rate 0.5\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.997 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.998 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.997 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.982 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.996 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.997 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.995 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 7.80%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.985 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.992 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.996 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.004 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.994 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.982 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.997 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.994 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.980 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.985 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.998 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.996 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.979 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.998 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.994 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.996 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.995 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.995 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.996 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.998 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.994 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.994 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.997 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.995 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.997 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.984 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 7.80%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.985 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.982 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.982 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.997 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.985 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.983 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.992 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.995 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.989 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 7.80%\n",
            "Early stopping!\n",
            "\n",
            "Train for: learning rate 0.1, droupout rate 0.75\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.949 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.784 |  Val. Acc: 35.00%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.805 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.763 |  Val. Acc: 35.00%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.778 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.743 |  Val. Acc: 35.00%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.771 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.716 |  Val. Acc: 43.60%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.646 | Train Acc: 35.00%\n",
            "\t Val. Loss: 1.666 |  Val. Acc: 45.00%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.580 | Train Acc: 40.71%\n",
            "\t Val. Loss: 1.605 |  Val. Acc: 43.60%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.564 | Train Acc: 36.43%\n",
            "\t Val. Loss: 1.547 |  Val. Acc: 41.00%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.539 | Train Acc: 38.57%\n",
            "\t Val. Loss: 1.494 |  Val. Acc: 41.80%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.471 | Train Acc: 42.14%\n",
            "\t Val. Loss: 1.445 |  Val. Acc: 46.80%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.320 | Train Acc: 51.43%\n",
            "\t Val. Loss: 1.395 |  Val. Acc: 55.60%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.230 | Train Acc: 62.86%\n",
            "\t Val. Loss: 1.335 |  Val. Acc: 68.20%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.169 | Train Acc: 69.29%\n",
            "\t Val. Loss: 1.264 |  Val. Acc: 71.80%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.139 | Train Acc: 57.86%\n",
            "\t Val. Loss: 1.198 |  Val. Acc: 69.80%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.083 | Train Acc: 64.29%\n",
            "\t Val. Loss: 1.143 |  Val. Acc: 67.60%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.022 | Train Acc: 68.57%\n",
            "\t Val. Loss: 1.090 |  Val. Acc: 70.00%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.951 | Train Acc: 67.86%\n",
            "\t Val. Loss: 1.043 |  Val. Acc: 73.80%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.960 | Train Acc: 65.71%\n",
            "\t Val. Loss: 1.009 |  Val. Acc: 76.80%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.948 | Train Acc: 67.14%\n",
            "\t Val. Loss: 0.989 |  Val. Acc: 77.00%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.884 | Train Acc: 71.43%\n",
            "\t Val. Loss: 0.967 |  Val. Acc: 78.60%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.908 | Train Acc: 74.29%\n",
            "\t Val. Loss: 0.940 |  Val. Acc: 78.80%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.759 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.909 |  Val. Acc: 79.00%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.783 | Train Acc: 77.86%\n",
            "\t Val. Loss: 0.886 |  Val. Acc: 77.60%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.810 | Train Acc: 74.29%\n",
            "\t Val. Loss: 0.852 |  Val. Acc: 77.80%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.754 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.854 |  Val. Acc: 77.80%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.728 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.829 |  Val. Acc: 78.60%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.734 | Train Acc: 76.43%\n",
            "\t Val. Loss: 0.796 |  Val. Acc: 78.40%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.777 | Train Acc: 75.71%\n",
            "\t Val. Loss: 0.814 |  Val. Acc: 76.80%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.758 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.821 |  Val. Acc: 76.80%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.787 | Train Acc: 73.57%\n",
            "\t Val. Loss: 0.776 |  Val. Acc: 79.00%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.681 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.791 |  Val. Acc: 78.40%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.606 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.795 |  Val. Acc: 77.80%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.724 | Train Acc: 74.29%\n",
            "\t Val. Loss: 0.757 |  Val. Acc: 78.60%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.630 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 79.00%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.697 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.748 |  Val. Acc: 79.40%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.687 | Train Acc: 76.43%\n",
            "\t Val. Loss: 0.733 |  Val. Acc: 79.00%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.633 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.713 |  Val. Acc: 79.20%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.554 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.715 |  Val. Acc: 80.00%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.572 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.713 |  Val. Acc: 79.60%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.720 | Train Acc: 77.86%\n",
            "\t Val. Loss: 0.701 |  Val. Acc: 77.20%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.649 | Train Acc: 77.86%\n",
            "\t Val. Loss: 0.725 |  Val. Acc: 77.60%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.601 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.735 |  Val. Acc: 77.40%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.524 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.712 |  Val. Acc: 77.00%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.537 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.717 |  Val. Acc: 78.20%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.588 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.721 |  Val. Acc: 78.80%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.557 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.726 |  Val. Acc: 80.20%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.526 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.732 |  Val. Acc: 79.60%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.582 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.722 |  Val. Acc: 79.20%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.607 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.707 |  Val. Acc: 76.60%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.497 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.705 |  Val. Acc: 77.40%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.625 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 78.20%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.582 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 77.20%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.507 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.727 |  Val. Acc: 77.60%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.529 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.718 |  Val. Acc: 79.20%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.593 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.681 |  Val. Acc: 78.60%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.598 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 79.00%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.535 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.682 |  Val. Acc: 78.00%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.484 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 78.00%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.543 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 78.00%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.603 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.675 |  Val. Acc: 78.40%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.510 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.670 |  Val. Acc: 80.20%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.469 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.673 |  Val. Acc: 81.80%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.579 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.668 |  Val. Acc: 81.40%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.434 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.660 |  Val. Acc: 79.80%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.528 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 79.20%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.596 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.672 |  Val. Acc: 76.80%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.495 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 77.40%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.497 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 78.60%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.528 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 78.80%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.500 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 79.00%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.526 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.676 |  Val. Acc: 79.00%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.469 | Train Acc: 91.43%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 79.80%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.468 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 79.20%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.487 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.659 |  Val. Acc: 77.80%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.446 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.666 |  Val. Acc: 78.80%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.460 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.668 |  Val. Acc: 78.80%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.487 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.668 |  Val. Acc: 76.20%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.503 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 77.00%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.493 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 81.00%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.469 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.665 |  Val. Acc: 81.00%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.415 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 81.60%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.470 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.669 |  Val. Acc: 80.60%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.563 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.676 |  Val. Acc: 78.80%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.523 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 77.20%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.444 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 77.20%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.428 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.659 |  Val. Acc: 77.20%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.454 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 80.60%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.433 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 81.40%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.560 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 79.80%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.396 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.666 |  Val. Acc: 78.20%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.505 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 78.60%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.432 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.659 |  Val. Acc: 78.20%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.424 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.668 |  Val. Acc: 76.40%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.457 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.653 |  Val. Acc: 78.00%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.484 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 78.40%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.564 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 79.40%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.492 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 79.80%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.497 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 80.20%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.421 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 80.40%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.461 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 81.00%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.425 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 77.60%\n",
            "Epoch: 101 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.380 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.670 |  Val. Acc: 78.20%\n",
            "Epoch: 102 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.413 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.666 |  Val. Acc: 77.60%\n",
            "Epoch: 103 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.403 | Train Acc: 92.86%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 78.40%\n",
            "Epoch: 104 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.448 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 79.60%\n",
            "Epoch: 105 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.409 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.644 |  Val. Acc: 80.80%\n",
            "Epoch: 106 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.457 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 81.20%\n",
            "Epoch: 107 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.414 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.629 |  Val. Acc: 81.40%\n",
            "Epoch: 108 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.371 | Train Acc: 92.14%\n",
            "\t Val. Loss: 0.653 |  Val. Acc: 79.60%\n",
            "Epoch: 109 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.452 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.679 |  Val. Acc: 78.20%\n",
            "Epoch: 110 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.494 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.657 |  Val. Acc: 79.20%\n",
            "Epoch: 111 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.445 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 81.00%\n",
            "Epoch: 112 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.422 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 81.60%\n",
            "Epoch: 113 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.566 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.650 |  Val. Acc: 81.20%\n",
            "Epoch: 114 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.429 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.658 |  Val. Acc: 79.20%\n",
            "Epoch: 115 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.477 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 77.20%\n",
            "Epoch: 116 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.487 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.664 |  Val. Acc: 78.20%\n",
            "Epoch: 117 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.509 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 80.40%\n",
            "Epoch: 118 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.424 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.673 |  Val. Acc: 81.40%\n",
            "Epoch: 119 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.465 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 81.80%\n",
            "Epoch: 120 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.495 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 78.60%\n",
            "Epoch: 121 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.432 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 78.40%\n",
            "Epoch: 122 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.441 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 77.20%\n",
            "Epoch: 123 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.422 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 81.00%\n",
            "Epoch: 124 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.409 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.659 |  Val. Acc: 81.80%\n",
            "Epoch: 125 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.441 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.672 |  Val. Acc: 80.60%\n",
            "Epoch: 126 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.456 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.658 |  Val. Acc: 81.40%\n",
            "Epoch: 127 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.432 | Train Acc: 92.14%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 80.00%\n",
            "Epoch: 128 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.459 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 78.60%\n",
            "Epoch: 129 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.413 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 79.00%\n",
            "Epoch: 130 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.404 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 79.00%\n",
            "Epoch: 131 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.379 | Train Acc: 92.86%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 79.00%\n",
            "Epoch: 132 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.449 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 80.80%\n",
            "Epoch: 133 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.392 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.675 |  Val. Acc: 79.80%\n",
            "Epoch: 134 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.486 | Train Acc: 92.14%\n",
            "\t Val. Loss: 0.663 |  Val. Acc: 78.00%\n",
            "Epoch: 135 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.370 | Train Acc: 92.14%\n",
            "\t Val. Loss: 0.664 |  Val. Acc: 78.40%\n",
            "Epoch: 136 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.507 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.664 |  Val. Acc: 78.80%\n",
            "Epoch: 137 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.406 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 79.60%\n",
            "Epoch: 138 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.395 | Train Acc: 91.43%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 79.20%\n",
            "Epoch: 139 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.441 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 80.20%\n",
            "Epoch: 140 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.450 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.655 |  Val. Acc: 79.60%\n",
            "Epoch: 141 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.395 | Train Acc: 91.43%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 79.80%\n",
            "Epoch: 142 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.482 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 81.20%\n",
            "Epoch: 143 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.441 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 81.00%\n",
            "Epoch: 144 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.403 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.641 |  Val. Acc: 81.00%\n",
            "Epoch: 145 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.460 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.651 |  Val. Acc: 79.20%\n",
            "Epoch: 146 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.482 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.653 |  Val. Acc: 77.60%\n",
            "Epoch: 147 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.507 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 79.40%\n",
            "Epoch: 148 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.388 | Train Acc: 94.29%\n",
            "\t Val. Loss: 0.640 |  Val. Acc: 79.20%\n",
            "Epoch: 149 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.470 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.646 |  Val. Acc: 79.20%\n",
            "Epoch: 150 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.420 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.660 |  Val. Acc: 79.60%\n",
            "Epoch: 151 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.465 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.662 |  Val. Acc: 79.40%\n",
            "Epoch: 152 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.347 | Train Acc: 91.43%\n",
            "\t Val. Loss: 0.644 |  Val. Acc: 81.00%\n",
            "Epoch: 153 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.472 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 81.40%\n",
            "Epoch: 154 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.450 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 80.40%\n",
            "Epoch: 155 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.456 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 79.60%\n",
            "Epoch: 156 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.453 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.658 |  Val. Acc: 79.00%\n",
            "Epoch: 157 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.484 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 79.60%\n",
            "Epoch: 158 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.506 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 79.20%\n",
            "Epoch: 159 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.420 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.632 |  Val. Acc: 79.40%\n",
            "Epoch: 160 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.440 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 81.40%\n",
            "Early stopping!\n",
            "\n",
            "Train for: learning rate 0.01, droupout rate 0.75\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.012 | Train Acc: 5.71%\n",
            "\t Val. Loss: 1.978 |  Val. Acc: 6.60%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.011 | Train Acc: 5.00%\n",
            "\t Val. Loss: 1.964 |  Val. Acc: 6.60%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 6.43%\n",
            "\t Val. Loss: 1.951 |  Val. Acc: 6.60%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.972 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 6.60%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 9.20%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.20%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.929 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.905 |  Val. Acc: 35.00%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.893 |  Val. Acc: 35.00%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.903 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.881 |  Val. Acc: 35.00%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.909 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.869 |  Val. Acc: 35.00%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.914 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.858 |  Val. Acc: 35.00%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.881 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.846 |  Val. Acc: 35.00%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.880 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.835 |  Val. Acc: 35.00%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.877 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.824 |  Val. Acc: 35.00%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.853 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.813 |  Val. Acc: 35.00%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.831 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.803 |  Val. Acc: 35.00%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.839 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.794 |  Val. Acc: 35.00%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.790 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.784 |  Val. Acc: 35.00%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.795 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.775 |  Val. Acc: 35.00%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.793 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.767 |  Val. Acc: 35.00%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.799 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.759 |  Val. Acc: 35.00%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.782 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.752 |  Val. Acc: 35.00%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.759 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.745 |  Val. Acc: 35.00%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.751 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.739 |  Val. Acc: 35.00%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.724 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.733 |  Val. Acc: 35.00%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.713 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.727 |  Val. Acc: 35.00%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.744 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.722 |  Val. Acc: 35.00%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.746 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.717 |  Val. Acc: 35.00%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.681 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.711 |  Val. Acc: 35.00%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.699 | Train Acc: 32.86%\n",
            "\t Val. Loss: 1.706 |  Val. Acc: 35.00%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.716 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.701 |  Val. Acc: 35.00%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.673 | Train Acc: 33.57%\n",
            "\t Val. Loss: 1.696 |  Val. Acc: 35.00%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.678 | Train Acc: 32.14%\n",
            "\t Val. Loss: 1.690 |  Val. Acc: 35.00%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.666 | Train Acc: 32.14%\n",
            "\t Val. Loss: 1.684 |  Val. Acc: 35.00%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.628 | Train Acc: 35.00%\n",
            "\t Val. Loss: 1.678 |  Val. Acc: 35.40%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.663 | Train Acc: 37.14%\n",
            "\t Val. Loss: 1.671 |  Val. Acc: 36.40%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.626 | Train Acc: 33.57%\n",
            "\t Val. Loss: 1.664 |  Val. Acc: 36.40%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.641 | Train Acc: 37.86%\n",
            "\t Val. Loss: 1.656 |  Val. Acc: 36.40%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.593 | Train Acc: 39.29%\n",
            "\t Val. Loss: 1.647 |  Val. Acc: 36.40%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.638 | Train Acc: 35.71%\n",
            "\t Val. Loss: 1.639 |  Val. Acc: 36.40%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.581 | Train Acc: 44.29%\n",
            "\t Val. Loss: 1.630 |  Val. Acc: 36.60%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.605 | Train Acc: 40.71%\n",
            "\t Val. Loss: 1.622 |  Val. Acc: 36.60%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.604 | Train Acc: 38.57%\n",
            "\t Val. Loss: 1.614 |  Val. Acc: 37.20%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.519 | Train Acc: 44.29%\n",
            "\t Val. Loss: 1.605 |  Val. Acc: 38.00%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.530 | Train Acc: 42.14%\n",
            "\t Val. Loss: 1.596 |  Val. Acc: 39.00%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.531 | Train Acc: 40.00%\n",
            "\t Val. Loss: 1.588 |  Val. Acc: 39.60%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.520 | Train Acc: 47.86%\n",
            "\t Val. Loss: 1.579 |  Val. Acc: 40.40%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.519 | Train Acc: 45.00%\n",
            "\t Val. Loss: 1.569 |  Val. Acc: 41.40%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.483 | Train Acc: 43.57%\n",
            "\t Val. Loss: 1.560 |  Val. Acc: 42.20%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.527 | Train Acc: 45.00%\n",
            "\t Val. Loss: 1.552 |  Val. Acc: 44.00%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.471 | Train Acc: 47.14%\n",
            "\t Val. Loss: 1.543 |  Val. Acc: 45.40%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.463 | Train Acc: 49.29%\n",
            "\t Val. Loss: 1.535 |  Val. Acc: 46.40%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.438 | Train Acc: 50.71%\n",
            "\t Val. Loss: 1.526 |  Val. Acc: 47.20%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.460 | Train Acc: 50.71%\n",
            "\t Val. Loss: 1.517 |  Val. Acc: 48.60%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.414 | Train Acc: 52.14%\n",
            "\t Val. Loss: 1.508 |  Val. Acc: 50.20%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.449 | Train Acc: 55.00%\n",
            "\t Val. Loss: 1.499 |  Val. Acc: 51.20%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.431 | Train Acc: 49.29%\n",
            "\t Val. Loss: 1.490 |  Val. Acc: 52.00%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.413 | Train Acc: 50.71%\n",
            "\t Val. Loss: 1.480 |  Val. Acc: 53.40%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.400 | Train Acc: 52.14%\n",
            "\t Val. Loss: 1.471 |  Val. Acc: 54.20%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.363 | Train Acc: 59.29%\n",
            "\t Val. Loss: 1.461 |  Val. Acc: 54.20%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.368 | Train Acc: 54.29%\n",
            "\t Val. Loss: 1.451 |  Val. Acc: 54.20%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.331 | Train Acc: 58.57%\n",
            "\t Val. Loss: 1.441 |  Val. Acc: 54.40%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.331 | Train Acc: 56.43%\n",
            "\t Val. Loss: 1.432 |  Val. Acc: 54.60%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.319 | Train Acc: 54.29%\n",
            "\t Val. Loss: 1.422 |  Val. Acc: 55.00%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.298 | Train Acc: 55.71%\n",
            "\t Val. Loss: 1.413 |  Val. Acc: 55.00%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.295 | Train Acc: 54.29%\n",
            "\t Val. Loss: 1.403 |  Val. Acc: 55.80%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.290 | Train Acc: 60.71%\n",
            "\t Val. Loss: 1.394 |  Val. Acc: 56.60%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.285 | Train Acc: 56.43%\n",
            "\t Val. Loss: 1.384 |  Val. Acc: 56.60%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.267 | Train Acc: 60.71%\n",
            "\t Val. Loss: 1.375 |  Val. Acc: 57.40%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.276 | Train Acc: 57.14%\n",
            "\t Val. Loss: 1.366 |  Val. Acc: 57.80%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.263 | Train Acc: 58.57%\n",
            "\t Val. Loss: 1.358 |  Val. Acc: 58.80%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.224 | Train Acc: 64.29%\n",
            "\t Val. Loss: 1.350 |  Val. Acc: 59.20%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.214 | Train Acc: 62.14%\n",
            "\t Val. Loss: 1.342 |  Val. Acc: 59.80%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.257 | Train Acc: 60.71%\n",
            "\t Val. Loss: 1.334 |  Val. Acc: 60.40%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.254 | Train Acc: 61.43%\n",
            "\t Val. Loss: 1.326 |  Val. Acc: 60.60%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.158 | Train Acc: 65.71%\n",
            "\t Val. Loss: 1.318 |  Val. Acc: 61.00%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.248 | Train Acc: 63.57%\n",
            "\t Val. Loss: 1.310 |  Val. Acc: 60.80%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.266 | Train Acc: 57.86%\n",
            "\t Val. Loss: 1.303 |  Val. Acc: 60.80%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.167 | Train Acc: 65.00%\n",
            "\t Val. Loss: 1.296 |  Val. Acc: 60.60%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.153 | Train Acc: 64.29%\n",
            "\t Val. Loss: 1.288 |  Val. Acc: 60.60%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.212 | Train Acc: 64.29%\n",
            "\t Val. Loss: 1.282 |  Val. Acc: 61.00%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.134 | Train Acc: 67.14%\n",
            "\t Val. Loss: 1.275 |  Val. Acc: 61.20%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.118 | Train Acc: 66.43%\n",
            "\t Val. Loss: 1.269 |  Val. Acc: 62.00%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.190 | Train Acc: 60.00%\n",
            "\t Val. Loss: 1.264 |  Val. Acc: 62.40%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.080 | Train Acc: 67.86%\n",
            "\t Val. Loss: 1.258 |  Val. Acc: 63.40%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.117 | Train Acc: 65.71%\n",
            "\t Val. Loss: 1.252 |  Val. Acc: 64.40%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.141 | Train Acc: 64.29%\n",
            "\t Val. Loss: 1.246 |  Val. Acc: 66.20%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.113 | Train Acc: 62.14%\n",
            "\t Val. Loss: 1.238 |  Val. Acc: 67.20%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.076 | Train Acc: 68.57%\n",
            "\t Val. Loss: 1.231 |  Val. Acc: 68.00%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.102 | Train Acc: 70.71%\n",
            "\t Val. Loss: 1.223 |  Val. Acc: 68.80%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.084 | Train Acc: 71.43%\n",
            "\t Val. Loss: 1.214 |  Val. Acc: 69.00%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.023 | Train Acc: 71.43%\n",
            "\t Val. Loss: 1.206 |  Val. Acc: 69.00%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.100 | Train Acc: 71.43%\n",
            "\t Val. Loss: 1.198 |  Val. Acc: 68.80%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.025 | Train Acc: 70.71%\n",
            "\t Val. Loss: 1.191 |  Val. Acc: 69.00%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.061 | Train Acc: 74.29%\n",
            "\t Val. Loss: 1.184 |  Val. Acc: 69.40%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.029 | Train Acc: 71.43%\n",
            "\t Val. Loss: 1.178 |  Val. Acc: 69.80%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.087 | Train Acc: 66.43%\n",
            "\t Val. Loss: 1.172 |  Val. Acc: 69.80%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.027 | Train Acc: 70.71%\n",
            "\t Val. Loss: 1.167 |  Val. Acc: 70.20%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.063 | Train Acc: 71.43%\n",
            "\t Val. Loss: 1.162 |  Val. Acc: 70.80%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.036 | Train Acc: 70.71%\n",
            "\t Val. Loss: 1.157 |  Val. Acc: 71.60%\n",
            "Epoch: 101 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.064 | Train Acc: 68.57%\n",
            "\t Val. Loss: 1.153 |  Val. Acc: 72.00%\n",
            "Epoch: 102 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.043 | Train Acc: 69.29%\n",
            "\t Val. Loss: 1.148 |  Val. Acc: 72.00%\n",
            "Epoch: 103 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.047 | Train Acc: 71.43%\n",
            "\t Val. Loss: 1.143 |  Val. Acc: 72.00%\n",
            "Epoch: 104 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.024 | Train Acc: 68.57%\n",
            "\t Val. Loss: 1.138 |  Val. Acc: 72.60%\n",
            "Epoch: 105 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.972 | Train Acc: 72.14%\n",
            "\t Val. Loss: 1.133 |  Val. Acc: 73.20%\n",
            "Epoch: 106 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.040 | Train Acc: 69.29%\n",
            "\t Val. Loss: 1.127 |  Val. Acc: 73.80%\n",
            "Epoch: 107 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.011 | Train Acc: 74.29%\n",
            "\t Val. Loss: 1.120 |  Val. Acc: 74.40%\n",
            "Epoch: 108 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.032 | Train Acc: 68.57%\n",
            "\t Val. Loss: 1.112 |  Val. Acc: 74.80%\n",
            "Epoch: 109 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.040 | Train Acc: 72.86%\n",
            "\t Val. Loss: 1.106 |  Val. Acc: 74.80%\n",
            "Epoch: 110 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.906 | Train Acc: 76.43%\n",
            "\t Val. Loss: 1.099 |  Val. Acc: 75.00%\n",
            "Epoch: 111 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.975 | Train Acc: 73.57%\n",
            "\t Val. Loss: 1.092 |  Val. Acc: 74.40%\n",
            "Epoch: 112 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.969 | Train Acc: 72.86%\n",
            "\t Val. Loss: 1.087 |  Val. Acc: 74.40%\n",
            "Epoch: 113 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.911 | Train Acc: 77.14%\n",
            "\t Val. Loss: 1.081 |  Val. Acc: 75.40%\n",
            "Epoch: 114 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.971 | Train Acc: 75.00%\n",
            "\t Val. Loss: 1.077 |  Val. Acc: 75.80%\n",
            "Epoch: 115 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.947 | Train Acc: 75.00%\n",
            "\t Val. Loss: 1.073 |  Val. Acc: 76.40%\n",
            "Epoch: 116 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.932 | Train Acc: 75.71%\n",
            "\t Val. Loss: 1.069 |  Val. Acc: 77.40%\n",
            "Epoch: 117 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.918 | Train Acc: 75.71%\n",
            "\t Val. Loss: 1.065 |  Val. Acc: 77.60%\n",
            "Epoch: 118 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.996 | Train Acc: 75.00%\n",
            "\t Val. Loss: 1.060 |  Val. Acc: 77.80%\n",
            "Epoch: 119 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.928 | Train Acc: 76.43%\n",
            "\t Val. Loss: 1.055 |  Val. Acc: 77.40%\n",
            "Epoch: 120 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.874 | Train Acc: 81.43%\n",
            "\t Val. Loss: 1.049 |  Val. Acc: 77.20%\n",
            "Epoch: 121 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.903 | Train Acc: 80.00%\n",
            "\t Val. Loss: 1.044 |  Val. Acc: 76.80%\n",
            "Epoch: 122 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.921 | Train Acc: 77.86%\n",
            "\t Val. Loss: 1.039 |  Val. Acc: 76.40%\n",
            "Epoch: 123 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.885 | Train Acc: 77.14%\n",
            "\t Val. Loss: 1.034 |  Val. Acc: 76.60%\n",
            "Epoch: 124 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.822 | Train Acc: 77.86%\n",
            "\t Val. Loss: 1.029 |  Val. Acc: 77.40%\n",
            "Epoch: 125 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.868 | Train Acc: 75.71%\n",
            "\t Val. Loss: 1.024 |  Val. Acc: 78.00%\n",
            "Epoch: 126 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.833 | Train Acc: 80.00%\n",
            "\t Val. Loss: 1.020 |  Val. Acc: 78.20%\n",
            "Epoch: 127 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.911 | Train Acc: 76.43%\n",
            "\t Val. Loss: 1.016 |  Val. Acc: 78.60%\n",
            "Epoch: 128 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.870 | Train Acc: 80.00%\n",
            "\t Val. Loss: 1.012 |  Val. Acc: 78.20%\n",
            "Epoch: 129 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.918 | Train Acc: 77.86%\n",
            "\t Val. Loss: 1.009 |  Val. Acc: 78.60%\n",
            "Epoch: 130 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.935 | Train Acc: 73.57%\n",
            "\t Val. Loss: 1.006 |  Val. Acc: 79.00%\n",
            "Epoch: 131 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.844 | Train Acc: 78.57%\n",
            "\t Val. Loss: 1.002 |  Val. Acc: 79.60%\n",
            "Epoch: 132 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.913 | Train Acc: 77.14%\n",
            "\t Val. Loss: 0.998 |  Val. Acc: 79.60%\n",
            "Epoch: 133 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.900 | Train Acc: 77.14%\n",
            "\t Val. Loss: 0.995 |  Val. Acc: 79.80%\n",
            "Epoch: 134 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.861 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.991 |  Val. Acc: 79.80%\n",
            "Epoch: 135 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.832 | Train Acc: 77.86%\n",
            "\t Val. Loss: 0.988 |  Val. Acc: 79.80%\n",
            "Epoch: 136 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.898 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.984 |  Val. Acc: 79.80%\n",
            "Epoch: 137 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.832 | Train Acc: 79.29%\n",
            "\t Val. Loss: 0.981 |  Val. Acc: 79.80%\n",
            "Epoch: 138 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.864 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.977 |  Val. Acc: 79.80%\n",
            "Epoch: 139 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.861 | Train Acc: 79.29%\n",
            "\t Val. Loss: 0.975 |  Val. Acc: 79.60%\n",
            "Epoch: 140 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.839 | Train Acc: 76.43%\n",
            "\t Val. Loss: 0.972 |  Val. Acc: 79.40%\n",
            "Epoch: 141 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.870 | Train Acc: 74.29%\n",
            "\t Val. Loss: 0.970 |  Val. Acc: 79.00%\n",
            "Epoch: 142 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.847 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.967 |  Val. Acc: 79.20%\n",
            "Epoch: 143 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.877 | Train Acc: 79.29%\n",
            "\t Val. Loss: 0.963 |  Val. Acc: 79.40%\n",
            "Epoch: 144 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.819 | Train Acc: 75.71%\n",
            "\t Val. Loss: 0.960 |  Val. Acc: 79.40%\n",
            "Epoch: 145 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.821 | Train Acc: 79.29%\n",
            "\t Val. Loss: 0.957 |  Val. Acc: 79.60%\n",
            "Epoch: 146 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.820 | Train Acc: 79.29%\n",
            "\t Val. Loss: 0.953 |  Val. Acc: 79.60%\n",
            "Epoch: 147 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.801 | Train Acc: 79.29%\n",
            "\t Val. Loss: 0.948 |  Val. Acc: 80.20%\n",
            "Epoch: 148 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.745 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.943 |  Val. Acc: 80.40%\n",
            "Epoch: 149 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.898 | Train Acc: 76.43%\n",
            "\t Val. Loss: 0.938 |  Val. Acc: 79.80%\n",
            "Epoch: 150 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.866 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.933 |  Val. Acc: 79.60%\n",
            "Epoch: 151 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.837 | Train Acc: 75.71%\n",
            "\t Val. Loss: 0.930 |  Val. Acc: 79.80%\n",
            "Epoch: 152 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.875 | Train Acc: 72.14%\n",
            "\t Val. Loss: 0.927 |  Val. Acc: 79.80%\n",
            "Epoch: 153 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.748 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.924 |  Val. Acc: 79.80%\n",
            "Epoch: 154 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.793 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.922 |  Val. Acc: 79.80%\n",
            "Epoch: 155 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.767 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.919 |  Val. Acc: 79.80%\n",
            "Epoch: 156 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.781 | Train Acc: 77.86%\n",
            "\t Val. Loss: 0.916 |  Val. Acc: 80.40%\n",
            "Epoch: 157 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.811 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.914 |  Val. Acc: 80.40%\n",
            "Epoch: 158 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.776 | Train Acc: 76.43%\n",
            "\t Val. Loss: 0.912 |  Val. Acc: 80.20%\n",
            "Epoch: 159 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.761 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.911 |  Val. Acc: 79.60%\n",
            "Epoch: 160 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.778 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.909 |  Val. Acc: 79.60%\n",
            "Epoch: 161 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.755 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.907 |  Val. Acc: 79.40%\n",
            "Epoch: 162 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.703 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.903 |  Val. Acc: 79.40%\n",
            "Epoch: 163 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.769 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.900 |  Val. Acc: 79.80%\n",
            "Epoch: 164 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.786 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.896 |  Val. Acc: 80.20%\n",
            "Epoch: 165 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.806 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.892 |  Val. Acc: 80.40%\n",
            "Epoch: 166 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.843 | Train Acc: 76.43%\n",
            "\t Val. Loss: 0.889 |  Val. Acc: 79.80%\n",
            "Epoch: 167 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.803 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.886 |  Val. Acc: 79.60%\n",
            "Epoch: 168 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.762 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.885 |  Val. Acc: 80.00%\n",
            "Epoch: 169 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.689 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.883 |  Val. Acc: 80.00%\n",
            "Epoch: 170 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.760 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.880 |  Val. Acc: 80.00%\n",
            "Epoch: 171 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.754 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.878 |  Val. Acc: 79.60%\n",
            "Epoch: 172 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.802 | Train Acc: 76.43%\n",
            "\t Val. Loss: 0.876 |  Val. Acc: 79.80%\n",
            "Epoch: 173 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.661 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.875 |  Val. Acc: 80.00%\n",
            "Epoch: 174 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.694 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.872 |  Val. Acc: 79.80%\n",
            "Epoch: 175 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.769 | Train Acc: 77.86%\n",
            "\t Val. Loss: 0.870 |  Val. Acc: 80.20%\n",
            "Epoch: 176 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.745 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.867 |  Val. Acc: 79.60%\n",
            "Epoch: 177 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.738 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.865 |  Val. Acc: 80.20%\n",
            "Epoch: 178 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.768 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.863 |  Val. Acc: 80.00%\n",
            "Epoch: 179 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.751 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.861 |  Val. Acc: 79.80%\n",
            "Epoch: 180 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.744 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.859 |  Val. Acc: 80.00%\n",
            "Epoch: 181 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.674 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.856 |  Val. Acc: 80.00%\n",
            "Epoch: 182 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.704 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.853 |  Val. Acc: 80.00%\n",
            "Epoch: 183 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.719 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.851 |  Val. Acc: 79.80%\n",
            "Epoch: 184 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.783 | Train Acc: 77.14%\n",
            "\t Val. Loss: 0.848 |  Val. Acc: 80.40%\n",
            "Epoch: 185 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.752 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.845 |  Val. Acc: 80.20%\n",
            "Epoch: 186 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.686 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.843 |  Val. Acc: 80.00%\n",
            "Epoch: 187 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.795 | Train Acc: 77.86%\n",
            "\t Val. Loss: 0.841 |  Val. Acc: 79.60%\n",
            "Epoch: 188 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.642 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.840 |  Val. Acc: 79.60%\n",
            "Epoch: 189 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.738 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.838 |  Val. Acc: 79.60%\n",
            "Epoch: 190 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.672 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.837 |  Val. Acc: 80.00%\n",
            "Epoch: 191 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.663 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.835 |  Val. Acc: 80.00%\n",
            "Epoch: 192 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.648 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.833 |  Val. Acc: 79.60%\n",
            "Epoch: 193 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.658 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.831 |  Val. Acc: 79.80%\n",
            "Epoch: 194 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.734 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.829 |  Val. Acc: 80.00%\n",
            "Epoch: 195 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.680 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.827 |  Val. Acc: 79.60%\n",
            "Epoch: 196 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.779 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.827 |  Val. Acc: 79.60%\n",
            "Epoch: 197 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.685 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.826 |  Val. Acc: 79.60%\n",
            "Epoch: 198 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.739 | Train Acc: 79.29%\n",
            "\t Val. Loss: 0.824 |  Val. Acc: 79.80%\n",
            "Epoch: 199 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.727 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.822 |  Val. Acc: 80.20%\n",
            "Epoch: 200 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.727 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.820 |  Val. Acc: 79.80%\n",
            "Epoch: 201 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.683 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.818 |  Val. Acc: 79.80%\n",
            "Epoch: 202 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.674 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.817 |  Val. Acc: 79.80%\n",
            "Epoch: 203 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.743 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.816 |  Val. Acc: 80.00%\n",
            "Epoch: 204 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.716 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.815 |  Val. Acc: 80.00%\n",
            "Epoch: 205 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.678 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.814 |  Val. Acc: 80.00%\n",
            "Epoch: 206 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.679 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.812 |  Val. Acc: 80.00%\n",
            "Epoch: 207 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.643 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.809 |  Val. Acc: 80.00%\n",
            "Epoch: 208 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.641 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.805 |  Val. Acc: 80.20%\n",
            "Epoch: 209 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.678 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.802 |  Val. Acc: 80.00%\n",
            "Epoch: 210 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.726 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.799 |  Val. Acc: 79.60%\n",
            "Epoch: 211 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.658 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.796 |  Val. Acc: 79.80%\n",
            "Epoch: 212 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.700 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.795 |  Val. Acc: 80.20%\n",
            "Epoch: 213 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.713 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.794 |  Val. Acc: 80.20%\n",
            "Epoch: 214 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.721 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.794 |  Val. Acc: 80.00%\n",
            "Epoch: 215 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.716 | Train Acc: 76.43%\n",
            "\t Val. Loss: 0.795 |  Val. Acc: 80.20%\n",
            "Epoch: 216 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.651 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.795 |  Val. Acc: 80.40%\n",
            "Epoch: 217 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.644 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.795 |  Val. Acc: 80.40%\n",
            "Epoch: 218 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.659 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.794 |  Val. Acc: 80.20%\n",
            "Epoch: 219 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.702 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.794 |  Val. Acc: 80.20%\n",
            "Epoch: 220 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.665 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.793 |  Val. Acc: 80.20%\n",
            "Epoch: 221 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.613 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.792 |  Val. Acc: 79.80%\n",
            "Epoch: 222 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.638 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.790 |  Val. Acc: 79.80%\n",
            "Epoch: 223 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.647 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.786 |  Val. Acc: 79.80%\n",
            "Epoch: 224 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.623 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.782 |  Val. Acc: 80.00%\n",
            "Epoch: 225 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.662 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.777 |  Val. Acc: 80.40%\n",
            "Epoch: 226 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.661 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.773 |  Val. Acc: 80.60%\n",
            "Epoch: 227 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.624 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.771 |  Val. Acc: 80.60%\n",
            "Epoch: 228 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.676 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.768 |  Val. Acc: 80.80%\n",
            "Epoch: 229 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.625 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.767 |  Val. Acc: 81.20%\n",
            "Epoch: 230 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.656 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.766 |  Val. Acc: 81.00%\n",
            "Epoch: 231 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.648 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.765 |  Val. Acc: 80.40%\n",
            "Epoch: 232 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.614 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.765 |  Val. Acc: 80.20%\n",
            "Epoch: 233 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.649 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.767 |  Val. Acc: 80.00%\n",
            "Epoch: 234 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.673 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.769 |  Val. Acc: 80.40%\n",
            "Epoch: 235 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.689 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.771 |  Val. Acc: 80.60%\n",
            "Epoch: 236 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.590 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.772 |  Val. Acc: 80.60%\n",
            "Epoch: 237 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.599 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.772 |  Val. Acc: 80.20%\n",
            "Epoch: 238 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.688 | Train Acc: 75.00%\n",
            "\t Val. Loss: 0.770 |  Val. Acc: 80.40%\n",
            "Epoch: 239 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.616 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.768 |  Val. Acc: 80.40%\n",
            "Epoch: 240 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.631 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.766 |  Val. Acc: 80.20%\n",
            "Epoch: 241 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.701 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.764 |  Val. Acc: 80.00%\n",
            "Epoch: 242 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.637 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.762 |  Val. Acc: 80.60%\n",
            "Epoch: 243 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.567 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.759 |  Val. Acc: 80.40%\n",
            "Epoch: 244 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.566 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.756 |  Val. Acc: 80.40%\n",
            "Epoch: 245 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.642 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.754 |  Val. Acc: 80.40%\n",
            "Epoch: 246 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.686 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.751 |  Val. Acc: 80.60%\n",
            "Epoch: 247 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.622 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.749 |  Val. Acc: 80.00%\n",
            "Epoch: 248 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.627 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.748 |  Val. Acc: 80.20%\n",
            "Epoch: 249 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.697 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.747 |  Val. Acc: 80.00%\n",
            "Epoch: 250 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.572 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.748 |  Val. Acc: 80.20%\n",
            "Epoch: 251 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.596 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.749 |  Val. Acc: 80.20%\n",
            "Epoch: 252 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.566 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.751 |  Val. Acc: 80.00%\n",
            "Epoch: 253 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.610 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.752 |  Val. Acc: 79.80%\n",
            "Epoch: 254 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.627 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.752 |  Val. Acc: 79.80%\n",
            "Epoch: 255 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.660 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.752 |  Val. Acc: 80.00%\n",
            "Epoch: 256 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.640 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.752 |  Val. Acc: 80.20%\n",
            "Epoch: 257 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.608 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.751 |  Val. Acc: 80.40%\n",
            "Epoch: 258 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.580 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.751 |  Val. Acc: 80.60%\n",
            "Epoch: 259 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.615 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.751 |  Val. Acc: 81.00%\n",
            "Epoch: 260 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.659 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.751 |  Val. Acc: 81.00%\n",
            "Epoch: 261 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.558 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.752 |  Val. Acc: 81.00%\n",
            "Epoch: 262 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.695 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.751 |  Val. Acc: 81.00%\n",
            "Epoch: 263 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.631 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.750 |  Val. Acc: 81.00%\n",
            "Epoch: 264 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.581 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.750 |  Val. Acc: 80.80%\n",
            "Epoch: 265 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.596 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.748 |  Val. Acc: 80.80%\n",
            "Epoch: 266 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.603 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.746 |  Val. Acc: 80.80%\n",
            "Epoch: 267 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.638 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.745 |  Val. Acc: 80.60%\n",
            "Epoch: 268 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.598 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 80.40%\n",
            "Epoch: 269 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.558 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 80.20%\n",
            "Epoch: 270 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.617 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 80.40%\n",
            "Epoch: 271 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.572 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 80.40%\n",
            "Epoch: 272 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.589 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 80.40%\n",
            "Epoch: 273 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.696 | Train Acc: 78.57%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 80.60%\n",
            "Epoch: 274 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.584 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 80.80%\n",
            "Epoch: 275 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.636 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 80.80%\n",
            "Epoch: 276 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.610 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.743 |  Val. Acc: 81.00%\n",
            "Epoch: 277 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.633 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.742 |  Val. Acc: 80.80%\n",
            "Epoch: 278 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.595 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.740 |  Val. Acc: 81.00%\n",
            "Epoch: 279 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.580 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.737 |  Val. Acc: 80.80%\n",
            "Epoch: 280 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.568 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.734 |  Val. Acc: 81.00%\n",
            "Epoch: 281 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.553 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.731 |  Val. Acc: 80.60%\n",
            "Epoch: 282 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.608 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.729 |  Val. Acc: 80.20%\n",
            "Epoch: 283 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.579 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.727 |  Val. Acc: 79.60%\n",
            "Epoch: 284 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.580 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.725 |  Val. Acc: 79.40%\n",
            "Epoch: 285 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.606 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.724 |  Val. Acc: 79.80%\n",
            "Epoch: 286 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.612 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.723 |  Val. Acc: 79.80%\n",
            "Epoch: 287 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.606 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.722 |  Val. Acc: 80.00%\n",
            "Epoch: 288 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.675 | Train Acc: 81.43%\n",
            "\t Val. Loss: 0.721 |  Val. Acc: 80.80%\n",
            "Epoch: 289 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.603 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.721 |  Val. Acc: 81.60%\n",
            "Epoch: 290 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.565 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.722 |  Val. Acc: 80.80%\n",
            "Epoch: 291 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.600 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.724 |  Val. Acc: 80.80%\n",
            "Epoch: 292 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.611 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.724 |  Val. Acc: 80.80%\n",
            "Epoch: 293 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.586 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.723 |  Val. Acc: 81.00%\n",
            "Epoch: 294 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.548 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.722 |  Val. Acc: 81.20%\n",
            "Epoch: 295 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.570 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.722 |  Val. Acc: 80.80%\n",
            "Epoch: 296 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.594 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.722 |  Val. Acc: 80.00%\n",
            "Epoch: 297 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.618 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.723 |  Val. Acc: 79.80%\n",
            "Epoch: 298 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.592 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.723 |  Val. Acc: 80.00%\n",
            "Epoch: 299 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.548 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.723 |  Val. Acc: 79.60%\n",
            "Epoch: 300 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.561 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.721 |  Val. Acc: 79.60%\n",
            "Epoch: 301 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.552 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.718 |  Val. Acc: 79.60%\n",
            "Epoch: 302 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.606 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.715 |  Val. Acc: 80.00%\n",
            "Epoch: 303 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.599 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.713 |  Val. Acc: 80.00%\n",
            "Epoch: 304 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.625 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.713 |  Val. Acc: 81.20%\n",
            "Epoch: 305 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.541 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.712 |  Val. Acc: 81.00%\n",
            "Epoch: 306 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.616 | Train Acc: 77.86%\n",
            "\t Val. Loss: 0.711 |  Val. Acc: 81.00%\n",
            "Epoch: 307 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.566 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.710 |  Val. Acc: 81.00%\n",
            "Epoch: 308 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.599 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.709 |  Val. Acc: 80.80%\n",
            "Epoch: 309 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.551 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.708 |  Val. Acc: 80.60%\n",
            "Epoch: 310 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.561 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 80.80%\n",
            "Epoch: 311 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.664 | Train Acc: 80.00%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 80.00%\n",
            "Epoch: 312 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.524 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 80.20%\n",
            "Epoch: 313 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.586 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.705 |  Val. Acc: 81.00%\n",
            "Epoch: 314 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.570 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.705 |  Val. Acc: 81.40%\n",
            "Epoch: 315 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.602 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 81.40%\n",
            "Epoch: 316 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.561 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 81.00%\n",
            "Epoch: 317 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.579 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.704 |  Val. Acc: 80.60%\n",
            "Epoch: 318 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.585 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.702 |  Val. Acc: 80.60%\n",
            "Epoch: 319 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.623 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.700 |  Val. Acc: 80.60%\n",
            "Epoch: 320 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.588 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 80.40%\n",
            "Epoch: 321 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.547 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 81.00%\n",
            "Epoch: 322 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.599 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 81.00%\n",
            "Epoch: 323 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.518 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 81.20%\n",
            "Epoch: 324 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.576 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 81.20%\n",
            "Epoch: 325 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.534 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 81.20%\n",
            "Epoch: 326 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.547 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 81.40%\n",
            "Epoch: 327 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.532 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 81.60%\n",
            "Epoch: 328 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.545 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 81.80%\n",
            "Epoch: 329 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.567 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 81.40%\n",
            "Epoch: 330 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.479 | Train Acc: 92.14%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 80.80%\n",
            "Epoch: 331 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.507 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 81.00%\n",
            "Epoch: 332 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.463 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 81.00%\n",
            "Epoch: 333 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.508 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 80.80%\n",
            "Epoch: 334 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.554 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 80.80%\n",
            "Epoch: 335 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.626 | Train Acc: 79.29%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 80.80%\n",
            "Epoch: 336 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.547 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 82.20%\n",
            "Epoch: 337 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.557 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 82.20%\n",
            "Epoch: 338 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.535 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 82.20%\n",
            "Epoch: 339 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.585 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 81.60%\n",
            "Epoch: 340 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.613 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 81.40%\n",
            "Epoch: 341 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.541 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 81.40%\n",
            "Epoch: 342 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.579 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 81.20%\n",
            "Epoch: 343 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.500 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 80.80%\n",
            "Epoch: 344 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.464 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 80.80%\n",
            "Epoch: 345 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.518 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 80.80%\n",
            "Epoch: 346 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.553 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 81.00%\n",
            "Epoch: 347 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.519 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 80.80%\n",
            "Epoch: 348 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.556 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 80.60%\n",
            "Epoch: 349 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.583 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 80.80%\n",
            "Epoch: 350 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.546 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.686 |  Val. Acc: 80.60%\n",
            "Epoch: 351 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.573 | Train Acc: 80.71%\n",
            "\t Val. Loss: 0.686 |  Val. Acc: 81.00%\n",
            "Epoch: 352 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.512 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.686 |  Val. Acc: 80.80%\n",
            "Epoch: 353 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.559 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 82.00%\n",
            "Epoch: 354 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.561 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 82.20%\n",
            "Epoch: 355 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.504 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 81.60%\n",
            "Epoch: 356 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.543 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 81.80%\n",
            "Epoch: 357 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.555 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 80.60%\n",
            "Epoch: 358 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.537 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 80.60%\n",
            "Epoch: 359 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.496 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.686 |  Val. Acc: 80.60%\n",
            "Epoch: 360 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.475 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.686 |  Val. Acc: 80.60%\n",
            "Epoch: 361 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.498 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 81.00%\n",
            "Epoch: 362 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.567 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 81.20%\n",
            "Epoch: 363 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.498 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.682 |  Val. Acc: 81.40%\n",
            "Epoch: 364 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.563 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.681 |  Val. Acc: 81.00%\n",
            "Epoch: 365 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.458 | Train Acc: 92.86%\n",
            "\t Val. Loss: 0.679 |  Val. Acc: 80.80%\n",
            "Epoch: 366 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.500 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.678 |  Val. Acc: 81.60%\n",
            "Epoch: 367 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.562 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 81.60%\n",
            "Epoch: 368 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.542 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.678 |  Val. Acc: 81.40%\n",
            "Epoch: 369 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.512 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.679 |  Val. Acc: 81.40%\n",
            "Epoch: 370 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.541 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 81.40%\n",
            "Epoch: 371 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.540 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 81.40%\n",
            "Epoch: 372 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.514 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 81.40%\n",
            "Epoch: 373 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.560 | Train Acc: 82.86%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 81.20%\n",
            "Epoch: 374 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.566 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.682 |  Val. Acc: 81.20%\n",
            "Epoch: 375 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.461 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.683 |  Val. Acc: 80.80%\n",
            "Epoch: 376 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.518 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.683 |  Val. Acc: 80.60%\n",
            "Epoch: 377 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.577 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 80.80%\n",
            "Epoch: 378 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.539 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 80.80%\n",
            "Epoch: 379 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.490 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 80.60%\n",
            "Epoch: 380 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.534 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.683 |  Val. Acc: 80.40%\n",
            "Epoch: 381 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.524 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.682 |  Val. Acc: 80.80%\n",
            "Epoch: 382 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.496 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 80.80%\n",
            "Epoch: 383 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.508 | Train Acc: 88.57%\n",
            "\t Val. Loss: 0.679 |  Val. Acc: 81.60%\n",
            "Epoch: 384 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.571 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 81.40%\n",
            "Epoch: 385 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.538 | Train Acc: 85.00%\n",
            "\t Val. Loss: 0.676 |  Val. Acc: 82.20%\n",
            "Epoch: 386 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.544 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.675 |  Val. Acc: 82.20%\n",
            "Epoch: 387 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.541 | Train Acc: 87.86%\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 81.60%\n",
            "Epoch: 388 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.532 | Train Acc: 90.00%\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 81.20%\n",
            "Epoch: 389 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.507 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 81.00%\n",
            "Epoch: 390 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.563 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.675 |  Val. Acc: 81.40%\n",
            "Epoch: 391 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.578 | Train Acc: 84.29%\n",
            "\t Val. Loss: 0.676 |  Val. Acc: 80.40%\n",
            "Epoch: 392 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.529 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.678 |  Val. Acc: 80.40%\n",
            "Epoch: 393 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.488 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 80.40%\n",
            "Epoch: 394 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.500 | Train Acc: 90.71%\n",
            "\t Val. Loss: 0.677 |  Val. Acc: 80.60%\n",
            "Epoch: 395 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.489 | Train Acc: 89.29%\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 80.60%\n",
            "Epoch: 396 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.495 | Train Acc: 86.43%\n",
            "\t Val. Loss: 0.670 |  Val. Acc: 81.00%\n",
            "Epoch: 397 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.569 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.667 |  Val. Acc: 80.60%\n",
            "Epoch: 398 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.489 | Train Acc: 87.14%\n",
            "\t Val. Loss: 0.667 |  Val. Acc: 81.20%\n",
            "Epoch: 399 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.548 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.666 |  Val. Acc: 81.20%\n",
            "Epoch: 400 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.569 | Train Acc: 83.57%\n",
            "\t Val. Loss: 0.667 |  Val. Acc: 81.20%\n",
            "\n",
            "Train for: learning rate 0.001, droupout rate 0.75\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.052 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.048 |  Val. Acc: 8.80%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.063 | Train Acc: 4.29%\n",
            "\t Val. Loss: 2.047 |  Val. Acc: 8.80%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.060 | Train Acc: 5.00%\n",
            "\t Val. Loss: 2.045 |  Val. Acc: 8.80%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.054 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.044 |  Val. Acc: 9.00%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.067 | Train Acc: 5.71%\n",
            "\t Val. Loss: 2.043 |  Val. Acc: 9.00%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.056 | Train Acc: 7.14%\n",
            "\t Val. Loss: 2.041 |  Val. Acc: 9.00%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.054 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.040 |  Val. Acc: 9.00%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.047 | Train Acc: 7.14%\n",
            "\t Val. Loss: 2.039 |  Val. Acc: 9.00%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.053 | Train Acc: 4.29%\n",
            "\t Val. Loss: 2.037 |  Val. Acc: 9.00%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.058 | Train Acc: 3.57%\n",
            "\t Val. Loss: 2.036 |  Val. Acc: 9.20%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.054 | Train Acc: 8.57%\n",
            "\t Val. Loss: 2.035 |  Val. Acc: 9.20%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.049 | Train Acc: 9.29%\n",
            "\t Val. Loss: 2.033 |  Val. Acc: 9.20%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.052 | Train Acc: 11.43%\n",
            "\t Val. Loss: 2.032 |  Val. Acc: 9.20%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.051 | Train Acc: 6.43%\n",
            "\t Val. Loss: 2.031 |  Val. Acc: 9.40%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.050 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.030 |  Val. Acc: 9.40%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.048 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.029 |  Val. Acc: 9.40%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.043 | Train Acc: 6.43%\n",
            "\t Val. Loss: 2.027 |  Val. Acc: 9.60%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.042 | Train Acc: 10.71%\n",
            "\t Val. Loss: 2.026 |  Val. Acc: 9.60%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.037 | Train Acc: 5.71%\n",
            "\t Val. Loss: 2.025 |  Val. Acc: 9.80%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.035 | Train Acc: 4.29%\n",
            "\t Val. Loss: 2.024 |  Val. Acc: 10.20%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.038 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.023 |  Val. Acc: 10.60%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.035 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.021 |  Val. Acc: 10.60%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.033 | Train Acc: 7.14%\n",
            "\t Val. Loss: 2.020 |  Val. Acc: 10.60%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.037 | Train Acc: 7.14%\n",
            "\t Val. Loss: 2.019 |  Val. Acc: 10.60%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.032 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.018 |  Val. Acc: 10.80%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.030 | Train Acc: 8.57%\n",
            "\t Val. Loss: 2.017 |  Val. Acc: 10.80%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.029 | Train Acc: 8.57%\n",
            "\t Val. Loss: 2.016 |  Val. Acc: 10.80%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.023 | Train Acc: 9.29%\n",
            "\t Val. Loss: 2.015 |  Val. Acc: 10.80%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.028 | Train Acc: 8.57%\n",
            "\t Val. Loss: 2.014 |  Val. Acc: 11.20%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.024 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.012 |  Val. Acc: 11.20%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.021 | Train Acc: 9.29%\n",
            "\t Val. Loss: 2.011 |  Val. Acc: 11.40%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.023 | Train Acc: 6.43%\n",
            "\t Val. Loss: 2.010 |  Val. Acc: 11.60%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.023 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.009 |  Val. Acc: 11.60%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.020 | Train Acc: 8.57%\n",
            "\t Val. Loss: 2.008 |  Val. Acc: 11.80%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.020 | Train Acc: 9.29%\n",
            "\t Val. Loss: 2.007 |  Val. Acc: 11.80%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.021 | Train Acc: 8.57%\n",
            "\t Val. Loss: 2.006 |  Val. Acc: 12.20%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.017 | Train Acc: 9.29%\n",
            "\t Val. Loss: 2.005 |  Val. Acc: 12.20%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.013 | Train Acc: 5.71%\n",
            "\t Val. Loss: 2.004 |  Val. Acc: 12.20%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.020 | Train Acc: 6.43%\n",
            "\t Val. Loss: 2.003 |  Val. Acc: 12.20%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.011 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.002 |  Val. Acc: 12.00%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.016 | Train Acc: 6.43%\n",
            "\t Val. Loss: 2.001 |  Val. Acc: 12.00%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.998 | Train Acc: 7.86%\n",
            "\t Val. Loss: 2.000 |  Val. Acc: 12.00%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.013 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.999 |  Val. Acc: 12.00%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.002 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.998 |  Val. Acc: 12.60%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.008 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.997 |  Val. Acc: 12.60%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.008 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.996 |  Val. Acc: 12.60%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.004 | Train Acc: 6.43%\n",
            "\t Val. Loss: 1.994 |  Val. Acc: 12.60%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.001 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.993 |  Val. Acc: 12.60%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.017 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.992 |  Val. Acc: 12.60%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.992 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.991 |  Val. Acc: 12.60%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.001 | Train Acc: 6.43%\n",
            "\t Val. Loss: 1.990 |  Val. Acc: 12.60%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.004 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.989 |  Val. Acc: 12.60%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.998 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.988 |  Val. Acc: 12.60%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.993 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.987 |  Val. Acc: 12.60%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.999 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.986 |  Val. Acc: 12.60%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.988 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.985 |  Val. Acc: 12.60%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.984 |  Val. Acc: 12.60%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.000 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.983 |  Val. Acc: 12.60%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.996 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.982 |  Val. Acc: 12.60%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 2.004 | Train Acc: 4.29%\n",
            "\t Val. Loss: 1.981 |  Val. Acc: 12.60%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.991 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.980 |  Val. Acc: 12.60%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.987 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.979 |  Val. Acc: 12.40%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.978 |  Val. Acc: 12.40%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.990 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.977 |  Val. Acc: 12.40%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.986 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.976 |  Val. Acc: 12.40%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.980 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.974 |  Val. Acc: 12.20%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.977 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.973 |  Val. Acc: 12.00%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.975 | Train Acc: 6.43%\n",
            "\t Val. Loss: 1.972 |  Val. Acc: 12.00%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.976 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.971 |  Val. Acc: 12.00%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.974 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.970 |  Val. Acc: 12.00%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.967 | Train Acc: 5.71%\n",
            "\t Val. Loss: 1.969 |  Val. Acc: 12.00%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.972 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.968 |  Val. Acc: 12.00%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.980 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.967 |  Val. Acc: 11.80%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.976 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.966 |  Val. Acc: 11.80%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.965 |  Val. Acc: 11.80%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.963 |  Val. Acc: 11.80%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.962 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.962 |  Val. Acc: 11.80%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.964 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.961 |  Val. Acc: 11.80%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.967 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.960 |  Val. Acc: 11.80%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.959 |  Val. Acc: 11.80%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.958 |  Val. Acc: 11.80%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.957 |  Val. Acc: 11.80%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.964 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.956 |  Val. Acc: 11.80%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.954 |  Val. Acc: 11.80%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.964 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.953 |  Val. Acc: 11.80%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.952 |  Val. Acc: 11.80%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.951 |  Val. Acc: 11.80%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.950 |  Val. Acc: 11.80%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.949 |  Val. Acc: 11.80%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.948 |  Val. Acc: 11.80%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.946 |  Val. Acc: 11.80%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.945 |  Val. Acc: 11.80%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.944 |  Val. Acc: 11.80%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 11.80%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 11.80%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 11.80%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 11.80%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 11.80%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.944 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 11.80%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 11.80%\n",
            "Epoch: 101 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 11.80%\n",
            "Epoch: 102 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 11.80%\n",
            "Epoch: 103 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 11.80%\n",
            "Epoch: 104 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 13.00%\n",
            "Epoch: 105 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 15.20%\n",
            "Epoch: 106 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 19.60%\n",
            "Epoch: 107 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.933 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 26.80%\n",
            "Epoch: 108 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 34.80%\n",
            "Epoch: 109 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 38.80%\n",
            "Epoch: 110 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.916 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 42.00%\n",
            "Epoch: 111 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.917 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 43.20%\n",
            "Epoch: 112 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 42.60%\n",
            "Epoch: 113 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.919 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 41.60%\n",
            "Epoch: 114 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 40.40%\n",
            "Epoch: 115 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 37.80%\n",
            "Epoch: 116 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.911 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 37.00%\n",
            "Epoch: 117 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.911 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 36.20%\n",
            "Epoch: 118 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 36.40%\n",
            "Epoch: 119 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.904 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.80%\n",
            "Epoch: 120 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.917 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.60%\n",
            "Epoch: 121 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.904 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.40%\n",
            "Epoch: 122 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.916 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.40%\n",
            "Epoch: 123 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.906 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.20%\n",
            "Epoch: 124 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.905 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.20%\n",
            "Epoch: 125 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.905 |  Val. Acc: 35.00%\n",
            "Epoch: 126 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.890 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.904 |  Val. Acc: 35.00%\n",
            "Epoch: 127 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.905 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.903 |  Val. Acc: 35.00%\n",
            "Epoch: 128 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.899 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.901 |  Val. Acc: 35.00%\n",
            "Epoch: 129 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.897 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.900 |  Val. Acc: 35.00%\n",
            "Epoch: 130 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.897 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.898 |  Val. Acc: 35.00%\n",
            "Epoch: 131 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.893 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.897 |  Val. Acc: 35.00%\n",
            "Epoch: 132 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.876 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.896 |  Val. Acc: 35.00%\n",
            "Epoch: 133 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.901 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.894 |  Val. Acc: 35.00%\n",
            "Epoch: 134 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.910 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.893 |  Val. Acc: 35.00%\n",
            "Epoch: 135 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.902 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.892 |  Val. Acc: 35.00%\n",
            "Epoch: 136 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.897 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.890 |  Val. Acc: 35.00%\n",
            "Epoch: 137 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.903 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.889 |  Val. Acc: 35.00%\n",
            "Epoch: 138 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.871 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.888 |  Val. Acc: 35.00%\n",
            "Epoch: 139 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.910 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.886 |  Val. Acc: 35.00%\n",
            "Epoch: 140 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.893 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.885 |  Val. Acc: 35.00%\n",
            "Epoch: 141 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.890 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.884 |  Val. Acc: 35.00%\n",
            "Epoch: 142 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.878 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.882 |  Val. Acc: 35.00%\n",
            "Epoch: 143 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.875 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.881 |  Val. Acc: 35.00%\n",
            "Epoch: 144 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.883 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.880 |  Val. Acc: 35.00%\n",
            "Epoch: 145 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.871 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.878 |  Val. Acc: 35.00%\n",
            "Epoch: 146 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.857 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.877 |  Val. Acc: 35.00%\n",
            "Epoch: 147 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.889 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.876 |  Val. Acc: 35.00%\n",
            "Epoch: 148 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.878 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.874 |  Val. Acc: 35.00%\n",
            "Epoch: 149 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.880 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.873 |  Val. Acc: 35.00%\n",
            "Epoch: 150 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.870 | Train Acc: 32.14%\n",
            "\t Val. Loss: 1.872 |  Val. Acc: 35.00%\n",
            "Epoch: 151 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.880 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.870 |  Val. Acc: 35.00%\n",
            "Epoch: 152 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.879 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.869 |  Val. Acc: 35.00%\n",
            "Epoch: 153 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.860 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.868 |  Val. Acc: 35.00%\n",
            "Epoch: 154 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.831 | Train Acc: 33.57%\n",
            "\t Val. Loss: 1.867 |  Val. Acc: 35.00%\n",
            "Epoch: 155 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.863 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.865 |  Val. Acc: 35.00%\n",
            "Epoch: 156 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.856 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.864 |  Val. Acc: 35.00%\n",
            "Epoch: 157 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.855 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.863 |  Val. Acc: 35.00%\n",
            "Epoch: 158 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.839 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.861 |  Val. Acc: 35.00%\n",
            "Epoch: 159 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.859 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.860 |  Val. Acc: 35.00%\n",
            "Epoch: 160 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.852 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.859 |  Val. Acc: 35.00%\n",
            "Epoch: 161 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.870 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.857 |  Val. Acc: 35.00%\n",
            "Epoch: 162 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.846 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.856 |  Val. Acc: 35.00%\n",
            "Epoch: 163 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.869 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.855 |  Val. Acc: 35.00%\n",
            "Epoch: 164 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.859 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.853 |  Val. Acc: 35.00%\n",
            "Epoch: 165 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.843 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.852 |  Val. Acc: 35.00%\n",
            "Epoch: 166 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.855 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.851 |  Val. Acc: 35.00%\n",
            "Epoch: 167 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.855 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.850 |  Val. Acc: 35.00%\n",
            "Epoch: 168 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.833 | Train Acc: 33.57%\n",
            "\t Val. Loss: 1.848 |  Val. Acc: 35.00%\n",
            "Epoch: 169 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.838 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.847 |  Val. Acc: 35.00%\n",
            "Epoch: 170 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.839 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.846 |  Val. Acc: 35.00%\n",
            "Epoch: 171 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.816 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.845 |  Val. Acc: 35.00%\n",
            "Epoch: 172 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.838 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.843 |  Val. Acc: 35.00%\n",
            "Epoch: 173 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.834 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.842 |  Val. Acc: 35.00%\n",
            "Epoch: 174 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.843 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.841 |  Val. Acc: 35.00%\n",
            "Epoch: 175 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.829 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.840 |  Val. Acc: 35.00%\n",
            "Epoch: 176 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.856 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.838 |  Val. Acc: 35.00%\n",
            "Epoch: 177 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.829 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.837 |  Val. Acc: 35.00%\n",
            "Epoch: 178 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.830 | Train Acc: 32.86%\n",
            "\t Val. Loss: 1.836 |  Val. Acc: 35.00%\n",
            "Epoch: 179 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.828 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.835 |  Val. Acc: 35.00%\n",
            "Epoch: 180 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.828 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.833 |  Val. Acc: 35.00%\n",
            "Epoch: 181 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.831 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.832 |  Val. Acc: 35.00%\n",
            "Epoch: 182 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.846 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.831 |  Val. Acc: 35.00%\n",
            "Epoch: 183 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.824 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.830 |  Val. Acc: 35.00%\n",
            "Epoch: 184 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.826 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.829 |  Val. Acc: 35.00%\n",
            "Epoch: 185 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.828 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.827 |  Val. Acc: 35.00%\n",
            "Epoch: 186 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.813 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.826 |  Val. Acc: 35.00%\n",
            "Epoch: 187 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.802 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.825 |  Val. Acc: 35.00%\n",
            "Epoch: 188 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.804 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.824 |  Val. Acc: 35.00%\n",
            "Epoch: 189 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.844 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.823 |  Val. Acc: 35.00%\n",
            "Epoch: 190 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.806 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.822 |  Val. Acc: 35.00%\n",
            "Epoch: 191 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.801 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.821 |  Val. Acc: 35.00%\n",
            "Epoch: 192 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.822 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.819 |  Val. Acc: 35.00%\n",
            "Epoch: 193 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.816 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.818 |  Val. Acc: 35.00%\n",
            "Epoch: 194 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.833 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.817 |  Val. Acc: 35.00%\n",
            "Epoch: 195 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.817 | Train Acc: 31.43%\n",
            "\t Val. Loss: 1.816 |  Val. Acc: 35.00%\n",
            "Epoch: 196 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.832 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.815 |  Val. Acc: 35.00%\n",
            "Epoch: 197 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.811 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.814 |  Val. Acc: 35.00%\n",
            "Epoch: 198 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.805 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.813 |  Val. Acc: 35.00%\n",
            "Epoch: 199 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.825 | Train Acc: 32.86%\n",
            "\t Val. Loss: 1.812 |  Val. Acc: 35.00%\n",
            "Epoch: 200 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.800 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.810 |  Val. Acc: 35.00%\n",
            "Epoch: 201 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.798 | Train Acc: 32.14%\n",
            "\t Val. Loss: 1.809 |  Val. Acc: 35.00%\n",
            "Epoch: 202 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.784 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.808 |  Val. Acc: 35.00%\n",
            "Epoch: 203 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.790 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.807 |  Val. Acc: 35.00%\n",
            "Epoch: 204 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.810 | Train Acc: 32.86%\n",
            "\t Val. Loss: 1.806 |  Val. Acc: 35.00%\n",
            "Epoch: 205 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.817 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.805 |  Val. Acc: 35.00%\n",
            "Epoch: 206 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.774 | Train Acc: 32.86%\n",
            "\t Val. Loss: 1.804 |  Val. Acc: 35.00%\n",
            "Epoch: 207 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.825 | Train Acc: 32.86%\n",
            "\t Val. Loss: 1.803 |  Val. Acc: 35.00%\n",
            "Epoch: 208 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.807 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.802 |  Val. Acc: 35.00%\n",
            "Epoch: 209 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.789 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.801 |  Val. Acc: 35.00%\n",
            "Epoch: 210 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.814 | Train Acc: 32.86%\n",
            "\t Val. Loss: 1.799 |  Val. Acc: 35.00%\n",
            "Early stopping!\n",
            "\n",
            "Train for: learning rate 0.0001, droupout rate 0.75\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.962 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 10.60%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 10.60%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 10.60%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 10.60%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.971 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 10.60%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 10.60%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.943 |  Val. Acc: 10.60%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 10.60%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 10.80%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 10.80%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 10.80%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 10.80%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 10.80%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 10.80%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 10.80%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 10.80%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 10.80%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 10.80%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.959 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 10.80%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 10.80%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.941 |  Val. Acc: 10.80%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 10.80%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 10.80%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 10.80%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.943 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 10.80%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 10.80%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 10.80%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 10.80%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.940 |  Val. Acc: 11.40%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.962 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 11.40%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 11.40%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 11.40%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 11.40%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 11.60%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 11.60%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.939 |  Val. Acc: 11.60%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 12.00%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 12.40%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 12.40%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.944 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 12.40%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 12.60%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 12.60%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.938 |  Val. Acc: 12.60%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 13.00%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 13.00%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 13.20%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 13.60%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 13.60%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 14.00%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.937 |  Val. Acc: 14.00%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 14.40%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.949 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 14.60%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 14.40%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 14.60%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 15.20%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 15.20%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 15.20%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.949 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 15.40%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 15.40%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 15.80%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.949 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 15.80%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 16.00%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 16.80%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.964 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 17.00%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 17.60%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 18.00%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.932 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 18.00%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 18.00%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.933 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 18.40%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 19.00%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 19.60%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 19.40%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 19.60%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 19.80%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 20.20%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.930 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 20.60%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 21.60%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.937 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 22.00%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 22.20%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 22.00%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.937 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 22.00%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.943 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 22.40%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 23.00%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 23.40%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.944 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 23.60%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.932 |  Val. Acc: 24.20%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 24.00%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.944 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 24.40%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 24.20%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 24.60%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 25.20%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 24.80%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.944 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.931 |  Val. Acc: 25.80%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 26.20%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 26.20%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 26.20%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 26.20%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.962 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 26.20%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.937 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 26.40%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 26.20%\n",
            "Epoch: 101 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.931 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 26.80%\n",
            "Epoch: 102 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 26.80%\n",
            "Epoch: 103 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 27.60%\n",
            "Epoch: 104 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.930 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 28.00%\n",
            "Epoch: 105 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 28.60%\n",
            "Epoch: 106 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 29.00%\n",
            "Epoch: 107 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 29.40%\n",
            "Epoch: 108 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 29.80%\n",
            "Epoch: 109 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.929 |  Val. Acc: 29.80%\n",
            "Epoch: 110 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.932 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 30.20%\n",
            "Epoch: 111 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.937 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 30.60%\n",
            "Epoch: 112 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 30.80%\n",
            "Epoch: 113 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 31.00%\n",
            "Epoch: 114 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 32.00%\n",
            "Epoch: 115 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.931 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 31.60%\n",
            "Epoch: 116 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.928 |  Val. Acc: 31.80%\n",
            "Epoch: 117 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 31.80%\n",
            "Epoch: 118 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 31.60%\n",
            "Epoch: 119 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 32.00%\n",
            "Epoch: 120 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 32.60%\n",
            "Epoch: 121 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.933 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 32.80%\n",
            "Epoch: 122 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 32.60%\n",
            "Epoch: 123 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 33.20%\n",
            "Epoch: 124 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.927 |  Val. Acc: 33.20%\n",
            "Epoch: 125 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 33.40%\n",
            "Epoch: 126 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 33.80%\n",
            "Epoch: 127 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 34.00%\n",
            "Epoch: 128 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 34.00%\n",
            "Epoch: 129 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 34.00%\n",
            "Epoch: 130 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 34.00%\n",
            "Epoch: 131 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.926 |  Val. Acc: 34.00%\n",
            "Epoch: 132 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.933 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 34.00%\n",
            "Epoch: 133 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 34.40%\n",
            "Epoch: 134 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 34.40%\n",
            "Epoch: 135 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.930 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 34.20%\n",
            "Epoch: 136 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.922 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 34.40%\n",
            "Epoch: 137 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 34.40%\n",
            "Epoch: 138 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 34.20%\n",
            "Epoch: 139 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.925 |  Val. Acc: 34.20%\n",
            "Epoch: 140 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 34.40%\n",
            "Epoch: 141 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 34.40%\n",
            "Epoch: 142 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 34.40%\n",
            "Epoch: 143 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 34.60%\n",
            "Epoch: 144 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.933 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 34.60%\n",
            "Epoch: 145 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 34.60%\n",
            "Epoch: 146 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.923 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 34.60%\n",
            "Epoch: 147 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 34.60%\n",
            "Epoch: 148 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 34.60%\n",
            "Epoch: 149 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 34.60%\n",
            "Epoch: 150 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 34.60%\n",
            "Epoch: 151 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 34.60%\n",
            "Epoch: 152 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.922 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 34.60%\n",
            "Epoch: 153 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 34.60%\n",
            "Epoch: 154 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 34.60%\n",
            "Epoch: 155 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.923 |  Val. Acc: 34.60%\n",
            "Epoch: 156 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.930 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 34.60%\n",
            "Epoch: 157 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 34.60%\n",
            "Epoch: 158 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 34.60%\n",
            "Epoch: 159 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 34.60%\n",
            "Epoch: 160 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 34.80%\n",
            "Epoch: 161 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.932 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 34.80%\n",
            "Epoch: 162 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.922 |  Val. Acc: 34.80%\n",
            "Epoch: 163 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.937 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 34.80%\n",
            "Epoch: 164 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 34.80%\n",
            "Epoch: 165 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 34.80%\n",
            "Epoch: 166 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.919 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 34.80%\n",
            "Epoch: 167 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 34.80%\n",
            "Epoch: 168 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.918 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 34.80%\n",
            "Epoch: 169 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.916 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 34.80%\n",
            "Epoch: 170 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.921 |  Val. Acc: 34.80%\n",
            "Epoch: 171 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.929 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 34.80%\n",
            "Epoch: 172 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 34.80%\n",
            "Epoch: 173 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 34.80%\n",
            "Epoch: 174 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 34.80%\n",
            "Epoch: 175 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 34.80%\n",
            "Epoch: 176 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 34.80%\n",
            "Epoch: 177 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.930 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 34.80%\n",
            "Epoch: 178 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.920 |  Val. Acc: 34.80%\n",
            "Epoch: 179 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 180 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 181 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.909 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 182 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 183 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 184 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 185 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 186 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.919 |  Val. Acc: 35.00%\n",
            "Epoch: 187 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 35.00%\n",
            "Epoch: 188 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.923 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 35.00%\n",
            "Epoch: 189 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 35.00%\n",
            "Epoch: 190 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.910 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 35.00%\n",
            "Epoch: 191 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 35.00%\n",
            "Epoch: 192 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.922 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 35.00%\n",
            "Epoch: 193 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.930 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 35.00%\n",
            "Epoch: 194 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.914 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 195 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.916 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 196 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.923 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 197 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 198 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.917 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 199 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 200 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 201 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.917 |  Val. Acc: 35.00%\n",
            "Epoch: 202 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.944 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.00%\n",
            "Epoch: 203 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.913 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.00%\n",
            "Epoch: 204 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.939 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.00%\n",
            "Epoch: 205 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.00%\n",
            "Epoch: 206 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.916 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.00%\n",
            "Epoch: 207 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.913 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.00%\n",
            "Epoch: 208 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.916 |  Val. Acc: 35.00%\n",
            "Epoch: 209 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 210 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 211 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.913 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 212 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.909 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 213 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.933 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 214 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 215 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 216 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.915 |  Val. Acc: 35.00%\n",
            "Epoch: 217 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.918 | Train Acc: 21.43%\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 35.00%\n",
            "Epoch: 218 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.913 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 35.00%\n",
            "Epoch: 219 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 35.00%\n",
            "Epoch: 220 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.929 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 35.00%\n",
            "Epoch: 221 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.941 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 35.00%\n",
            "Epoch: 222 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.933 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 35.00%\n",
            "Epoch: 223 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.922 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.914 |  Val. Acc: 35.00%\n",
            "Epoch: 224 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 225 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 226 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.932 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 227 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.909 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 228 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 229 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 230 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.903 | Train Acc: 35.71%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 231 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.923 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.913 |  Val. Acc: 35.00%\n",
            "Epoch: 232 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.00%\n",
            "Epoch: 233 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.931 | Train Acc: 22.14%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.00%\n",
            "Epoch: 234 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.921 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.00%\n",
            "Epoch: 235 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.914 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.00%\n",
            "Epoch: 236 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.00%\n",
            "Epoch: 237 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.916 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.00%\n",
            "Epoch: 238 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.922 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 35.00%\n",
            "Epoch: 239 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.00%\n",
            "Epoch: 240 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.00%\n",
            "Epoch: 241 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.924 | Train Acc: 22.86%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.00%\n",
            "Epoch: 242 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.934 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.00%\n",
            "Epoch: 243 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.00%\n",
            "Epoch: 244 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.911 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.00%\n",
            "Epoch: 245 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.917 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.911 |  Val. Acc: 35.00%\n",
            "Epoch: 246 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.920 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.910 |  Val. Acc: 35.00%\n",
            "Epoch: 247 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.923 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.910 |  Val. Acc: 35.00%\n",
            "Epoch: 248 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.910 |  Val. Acc: 35.00%\n",
            "Epoch: 249 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.916 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.910 |  Val. Acc: 35.00%\n",
            "Epoch: 250 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.915 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.910 |  Val. Acc: 35.00%\n",
            "Epoch: 251 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.909 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.910 |  Val. Acc: 35.00%\n",
            "Epoch: 252 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.912 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.910 |  Val. Acc: 35.00%\n",
            "Epoch: 253 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.927 | Train Acc: 30.71%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 254 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.908 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 255 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.906 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 256 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 257 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 258 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.915 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 259 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 260 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.926 | Train Acc: 30.00%\n",
            "\t Val. Loss: 1.909 |  Val. Acc: 35.00%\n",
            "Epoch: 261 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.908 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.00%\n",
            "Epoch: 262 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.922 | Train Acc: 20.00%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.00%\n",
            "Epoch: 263 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.906 | Train Acc: 32.14%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.00%\n",
            "Epoch: 264 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.925 | Train Acc: 23.57%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.00%\n",
            "Epoch: 265 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.930 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.00%\n",
            "Epoch: 266 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.906 | Train Acc: 28.57%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.00%\n",
            "Epoch: 267 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.913 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.908 |  Val. Acc: 35.00%\n",
            "Epoch: 268 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.915 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.00%\n",
            "Epoch: 269 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.907 | Train Acc: 25.71%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.00%\n",
            "Epoch: 270 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.908 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.00%\n",
            "Epoch: 271 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.917 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.00%\n",
            "Epoch: 272 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.920 | Train Acc: 26.43%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.00%\n",
            "Epoch: 273 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.911 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.00%\n",
            "Epoch: 274 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 27.14%\n",
            "\t Val. Loss: 1.907 |  Val. Acc: 35.00%\n",
            "Epoch: 275 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.907 | Train Acc: 33.57%\n",
            "\t Val. Loss: 1.906 |  Val. Acc: 35.00%\n",
            "Epoch: 276 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.916 | Train Acc: 25.00%\n",
            "\t Val. Loss: 1.906 |  Val. Acc: 35.00%\n",
            "Epoch: 277 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.919 | Train Acc: 27.86%\n",
            "\t Val. Loss: 1.906 |  Val. Acc: 35.00%\n",
            "Epoch: 278 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.913 | Train Acc: 29.29%\n",
            "\t Val. Loss: 1.906 |  Val. Acc: 35.00%\n",
            "Early stopping!\n",
            "\n",
            "Train for: learning rate 1e-05, droupout rate 0.75\n",
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.975 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.943 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.968 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 19.29%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 16 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 17 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 18 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.967 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 19 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 20 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 21 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 22 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.959 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 23 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 24 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.979 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.60%\n",
            "Epoch: 25 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 26 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 27 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 28 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 29 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 30 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 31 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 32 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 33 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.962 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 34 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 35 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 36 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 37 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 38 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 39 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.964 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 40 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 41 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 42 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 43 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 44 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 45 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 46 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 47 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 48 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 49 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 50 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.967 | Train Acc: 6.43%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 51 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.935 |  Val. Acc: 6.80%\n",
            "Epoch: 52 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 6.80%\n",
            "Epoch: 53 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 6.80%\n",
            "Epoch: 54 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 6.80%\n",
            "Epoch: 55 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.962 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 6.80%\n",
            "Epoch: 56 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.970 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 6.80%\n",
            "Epoch: 57 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.975 | Train Acc: 5.71%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 6.80%\n",
            "Epoch: 58 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 59 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 60 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 61 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 62 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 63 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 64 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 65 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 66 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 67 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 68 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 69 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 70 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 5.71%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 71 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.971 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 72 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 73 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 74 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 75 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 76 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 15.71%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 77 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 78 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 79 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 80 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 81 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 82 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.946 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 83 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 24.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 84 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.972 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 85 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 86 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 87 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.940 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 88 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 89 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.949 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 90 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.949 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 91 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.942 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 92 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 93 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.965 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 94 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.949 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 95 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 96 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 97 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 98 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.944 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 99 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 100 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 101 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.956 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 102 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 103 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 104 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 14.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 105 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 106 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.928 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 107 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.962 | Train Acc: 7.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 108 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 109 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 110 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.974 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 111 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 112 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.967 | Train Acc: 7.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 113 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.969 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 114 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 115 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 116 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.959 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 117 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.935 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 118 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.967 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 119 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 120 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 121 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.967 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 122 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.953 | Train Acc: 17.86%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 123 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.943 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 124 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.959 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 125 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.936 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 126 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 127 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.960 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 128 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 8.57%\n",
            "\t Val. Loss: 1.934 |  Val. Acc: 7.20%\n",
            "Epoch: 129 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 130 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.972 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 131 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 132 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 133 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 134 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 135 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.945 | Train Acc: 17.14%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 136 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 137 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 138 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 139 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.938 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 140 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.961 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 141 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.974 | Train Acc: 9.29%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 142 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.948 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 143 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 144 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 16.43%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 145 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.973 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 146 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.954 | Train Acc: 10.71%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 147 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.955 | Train Acc: 15.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 148 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.966 | Train Acc: 12.14%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 149 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.950 | Train Acc: 18.57%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 150 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.944 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 151 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.958 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 152 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.952 | Train Acc: 20.71%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 153 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.947 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 154 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.951 | Train Acc: 12.86%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 155 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.963 | Train Acc: 10.00%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 156 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.957 | Train Acc: 13.57%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Epoch: 157 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.959 | Train Acc: 11.43%\n",
            "\t Val. Loss: 1.933 |  Val. Acc: 7.20%\n",
            "Early stopping!\n",
            "Optimization Finished!\n",
            "\n",
            "Best model: learning rate 0.1, droupout rate 0.5\n",
            "0.8220000000000001\n",
            "Test Loss: 1.936 | Test Acc: 0.08\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}